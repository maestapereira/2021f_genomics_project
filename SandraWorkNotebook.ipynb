{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gfuSLyKzFiJT"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os"],"id":"gfuSLyKzFiJT"},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmwZoC5kFiJW"},"outputs":[],"source":["# import data into dataframe\n","df_raw = pd.read_csv('raw_data.zip', compression = 'zip').drop(columns=['Unnamed: 0'])\n","df_feature = pd.read_csv('feature_data.zip', compression = 'zip').drop(columns=['Unnamed: 0'])\n","df_labels = pd.read_csv('label_data.zip', compression = 'zip').drop(columns=['Unnamed: 0'])"],"id":"RmwZoC5kFiJW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0P_qj2TFiJX","outputId":"70b8bf85-50a3-4830-b9a7-dd5dab81bd2f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>5-alpha_reductase_inhibitor</th>\n","      <th>11-beta-hsd1_inhibitor</th>\n","      <th>acat_inhibitor</th>\n","      <th>acetylcholine_receptor_agonist</th>\n","      <th>acetylcholine_receptor_antagonist</th>\n","      <th>acetylcholinesterase_inhibitor</th>\n","      <th>adenosine_receptor_agonist</th>\n","      <th>adenosine_receptor_antagonist</th>\n","      <th>adenylyl_cyclase_activator</th>\n","      <th>...</th>\n","      <th>tropomyosin_receptor_kinase_inhibitor</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 207 columns</p>\n","</div>"],"text/plain":["             id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n","0  id_000644bb2                            0                       0   \n","1  id_000779bfc                            0                       0   \n","2  id_000a6266a                            0                       0   \n","3  id_0015fd391                            0                       0   \n","4  id_001626bd3                            0                       0   \n","\n","   acat_inhibitor  acetylcholine_receptor_agonist  \\\n","0               0                               0   \n","1               0                               0   \n","2               0                               0   \n","3               0                               0   \n","4               0                               0   \n","\n","   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n","0                                  0                               0   \n","1                                  0                               0   \n","2                                  0                               0   \n","3                                  0                               0   \n","4                                  0                               0   \n","\n","   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n","0                           0                              0   \n","1                           0                              0   \n","2                           0                              0   \n","3                           0                              0   \n","4                           0                              0   \n","\n","   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n","0                           0  ...                                      0   \n","1                           0  ...                                      0   \n","2                           0  ...                                      0   \n","3                           0  ...                                      0   \n","4                           0  ...                                      0   \n","\n","   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n","0             0                0                  0   \n","1             0                0                  0   \n","2             0                0                  0   \n","3             0                0                  0   \n","4             0                0                  0   \n","\n","   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n","0                          0                                      0   \n","1                          0                                      0   \n","2                          0                                      0   \n","3                          0                                      0   \n","4                          0                                      0   \n","\n","   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n","0                0          0                           0              0  \n","1                0          0                           0              0  \n","2                0          0                           0              0  \n","3                0          0                           0              0  \n","4                0          0                           0              0  \n","\n","[5 rows x 207 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_raw.head()"],"id":"K0P_qj2TFiJX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-lNmO5hFiJY","outputId":"e72e8ecc-38b3-42e3-c234-b56350d56924"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>with_drug</th>\n","      <th>time</th>\n","      <th>dosage</th>\n","      <th>drug</th>\n","      <th>g-0</th>\n","      <th>g-1</th>\n","      <th>g-2</th>\n","      <th>g-3</th>\n","      <th>g-4</th>\n","      <th>...</th>\n","      <th>c-90</th>\n","      <th>c-91</th>\n","      <th>c-92</th>\n","      <th>c-93</th>\n","      <th>c-94</th>\n","      <th>c-95</th>\n","      <th>c-96</th>\n","      <th>c-97</th>\n","      <th>c-98</th>\n","      <th>c-99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>b68db1d53</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>...</td>\n","      <td>0.2862</td>\n","      <td>0.2584</td>\n","      <td>0.8076</td>\n","      <td>0.5523</td>\n","      <td>-0.1912</td>\n","      <td>0.6584</td>\n","      <td>-0.3981</td>\n","      <td>0.2139</td>\n","      <td>0.3801</td>\n","      <td>0.4176</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>df89a8e5a</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>...</td>\n","      <td>-0.4265</td>\n","      <td>0.7543</td>\n","      <td>0.4708</td>\n","      <td>0.0230</td>\n","      <td>0.2957</td>\n","      <td>0.4899</td>\n","      <td>0.1522</td>\n","      <td>0.1241</td>\n","      <td>0.6077</td>\n","      <td>0.7371</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>18bb41b2c</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>...</td>\n","      <td>-0.7250</td>\n","      <td>-0.6297</td>\n","      <td>0.6103</td>\n","      <td>0.0223</td>\n","      <td>-1.3240</td>\n","      <td>-0.3174</td>\n","      <td>-0.6417</td>\n","      <td>-0.2187</td>\n","      <td>-1.4080</td>\n","      <td>0.6931</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>8c7f86626</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>...</td>\n","      <td>-2.0990</td>\n","      <td>-0.6441</td>\n","      <td>-5.6300</td>\n","      <td>-1.3780</td>\n","      <td>-0.8632</td>\n","      <td>-1.2880</td>\n","      <td>-1.6210</td>\n","      <td>-0.8784</td>\n","      <td>-0.3876</td>\n","      <td>-0.8154</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>7cbed3131</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>...</td>\n","      <td>0.0042</td>\n","      <td>0.0048</td>\n","      <td>0.6670</td>\n","      <td>1.0690</td>\n","      <td>0.5523</td>\n","      <td>-0.3031</td>\n","      <td>0.1094</td>\n","      <td>0.2885</td>\n","      <td>-0.3786</td>\n","      <td>0.7125</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 877 columns</p>\n","</div>"],"text/plain":["             id  with_drug  time dosage       drug     g-0     g-1     g-2  \\\n","0  id_000644bb2       True    24     D1  b68db1d53  1.0620  0.5577 -0.2479   \n","1  id_000779bfc       True    72     D1  df89a8e5a  0.0743  0.4087  0.2991   \n","2  id_000a6266a       True    48     D1  18bb41b2c  0.6280  0.5817  1.5540   \n","3  id_0015fd391       True    48     D1  8c7f86626 -0.5138 -0.2491 -0.2656   \n","4  id_001626bd3       True    72     D2  7cbed3131 -0.3254 -0.4009  0.9700   \n","\n","      g-3     g-4  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n","0 -0.6208 -0.1944  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n","1  0.0604  1.0190  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n","2 -0.0764 -0.0323  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n","3  0.5288  4.0620  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n","4  0.6919  1.4180  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n","\n","     c-96    c-97    c-98    c-99  \n","0 -0.3981  0.2139  0.3801  0.4176  \n","1  0.1522  0.1241  0.6077  0.7371  \n","2 -0.6417 -0.2187 -1.4080  0.6931  \n","3 -1.6210 -0.8784 -0.3876 -0.8154  \n","4  0.1094  0.2885 -0.3786  0.7125  \n","\n","[5 rows x 877 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_feature.head()"],"id":"a-lNmO5hFiJY"},{"cell_type":"markdown","source":["## IGNORE ABOVE"],"metadata":{"id":"UaXs41Xu1l9U"},"id":"UaXs41Xu1l9U"},{"cell_type":"code","source":["! pip install autogluon"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJYF14r_I6k2","executionInfo":{"status":"ok","timestamp":1639526062376,"user_tz":300,"elapsed":5913,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"bbdb4871-cd2f-4933-edaa-347b7bb7753c"},"id":"EJYF14r_I6k2","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: autogluon in /usr/local/lib/python3.7/dist-packages (0.3.1)\n","Requirement already satisfied: autogluon.features==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n","Requirement already satisfied: autogluon.extra==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n","Requirement already satisfied: autogluon.text==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n","Requirement already satisfied: autogluon.core==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n","Requirement already satisfied: autogluon.tabular[all]==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n","Requirement already satisfied: autogluon.mxnet==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n","Requirement already satisfied: autogluon.vision==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n","Requirement already satisfied: numpy<1.22,>=1.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.19.5)\n","Requirement already satisfied: scipy<1.7,>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.6.3)\n","Requirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2021.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2.23.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.20.24)\n","Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.3)\n","Requirement already satisfied: dill<1.0,>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.3.4)\n","Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.1.5)\n","Requirement already satisfied: distributed>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2021.12.0)\n","Requirement already satisfied: ConfigSpace==0.4.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.4.19)\n","Requirement already satisfied: graphviz<1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (3.2.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.29.24)\n","Requirement already satisfied: scikit-learn<0.25,>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.24.2)\n","Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (4.62.3)\n","Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (5.1.1)\n","Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2.8.1)\n","Requirement already satisfied: gluoncv<0.10.5,>=0.10.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.1->autogluon) (0.10.4.post4)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.1->autogluon) (3.6.4)\n","Requirement already satisfied: openml in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.1->autogluon) (0.12.2)\n","Requirement already satisfied: Pillow<8.4.0,>=8.3.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.mxnet==0.3.1->autogluon) (8.3.2)\n","Requirement already satisfied: psutil<5.9,>=5.7.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (5.8.0)\n","Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (2.6.3)\n","Requirement already satisfied: lightgbm<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (3.3.1)\n","Requirement already satisfied: catboost<0.26,>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (0.25.1)\n","Requirement already satisfied: fastai<3.0,>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (2.5.3)\n","Requirement already satisfied: xgboost<1.5,>=1.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (1.4.2)\n","Requirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (1.10.0+cu111)\n","Requirement already satisfied: autogluon-contrib-nlp==0.0.1b20210201 in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.3.1->autogluon) (0.0.1b20210201)\n","Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.1.95)\n","Requirement already satisfied: flake8 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (4.0.1)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.9.4)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.0.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.17.3)\n","Requirement already satisfied: sacremoses>=0.0.38 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.0.46)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.1.8)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2019.12.20)\n","Requirement already satisfied: contextvars in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.4)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.0.0)\n","Requirement already satisfied: timm-clean==0.4.12 in /usr/local/lib/python3.7/dist-packages (from autogluon.vision==0.3.1->autogluon) (0.4.12)\n","Requirement already satisfied: d8<1.0,>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.vision==0.3.1->autogluon) (0.0.2.post0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.19->autogluon.core==0.3.1->autogluon) (3.0.6)\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.3.1->autogluon) (0.16.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (4.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (1.15.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (2.0.2)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (1.5.12)\n","Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.0)\n","Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (1.2.0)\n","Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (0.11.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (3.13)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (21.3)\n","Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (2021.11.1)\n","Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (7.1.2)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.7.0)\n","Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.4.0)\n","Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.0)\n","Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.11.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (57.4.0)\n","Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.2.4)\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.0)\n","Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.0.5)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (21.1.3)\n","Requirement already satisfied: fastcore<1.4,>=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.3.27)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.11.1+cu111)\n","Requirement already satisfied: autocfg in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.1->autogluon) (0.0.8)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.1->autogluon) (2.3.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.1->autogluon) (4.1.2.30)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.3.1->autogluon) (0.37.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2.8.2)\n","Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.1->autogluon) (1.4.0)\n","Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.1->autogluon) (36.0.1)\n","Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.1->autogluon) (3.2.0)\n","Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (2.21)\n","Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask>=2.6.0->autogluon.core==0.3.1->autogluon) (0.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses>=0.0.38->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.3.1->autogluon) (3.0.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (7.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.0.6)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.6)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.8.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.4.1)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (4.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (2.10)\n","Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.1)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.1->autogluon) (0.5.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.1->autogluon) (0.10.0)\n","Requirement already satisfied: botocore<1.24.0,>=1.23.24 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.1->autogluon) (1.23.24)\n","Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.7/dist-packages (from contextvars->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.16)\n","Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.4.0)\n","Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.6.1)\n","Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.8.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (5.0.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (0.11.0)\n","Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.1->autogluon) (0.12.0)\n","Requirement already satisfied: minio in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.1->autogluon) (7.1.2)\n","Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.1->autogluon) (2.5.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (1.3.3)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.11.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (21.2.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (8.12.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (0.7.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (1.3)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.4.4)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.8.9)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"I64j0FJ7FiJa","executionInfo":{"status":"ok","timestamp":1639526067134,"user_tz":300,"elapsed":4763,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"outputs":[],"source":["import sys\n","import os\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","import torch.nn as nn\n","import pandas as pd\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.utils.data as Data\n","\n","from tensorflow import keras\n","\n","from torch.optim import Adam, SGD\n","from sklearn.metrics import confusion_matrix\n","from keras.layers import Dense, Bidirectional, Conv1D, MaxPool1D, Flatten, Dropout\n","from keras.layers import Input\n","from keras.models import Model\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.layers import BatchNormalization\n","import keras\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","from sklearn.metrics import ConfusionMatrixDisplay, precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Add"],"id":"I64j0FJ7FiJa"},{"cell_type":"code","source":["from autogluon.tabular import TabularDataset, TabularPredictor\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from tensorflow.keras.layers import SimpleRNN, LSTM"],"metadata":{"id":"WStCXORcI3Yh","executionInfo":{"status":"ok","timestamp":1639526068232,"user_tz":300,"elapsed":1111,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"WStCXORcI3Yh","execution_count":3,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"1q9wAJmb6zMg","executionInfo":{"status":"ok","timestamp":1639526068233,"user_tz":300,"elapsed":5,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"1q9wAJmb6zMg","execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0H_j8G_FiJa","executionInfo":{"status":"ok","timestamp":1639526068862,"user_tz":300,"elapsed":633,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"fa831f50-2420-49a4-e375-67bc7464b8fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"id":"Y0H_j8G_FiJa"},{"cell_type":"code","execution_count":6,"metadata":{"id":"HMhdxmoNFiJb","executionInfo":{"status":"ok","timestamp":1639526068862,"user_tz":300,"elapsed":2,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"outputs":[],"source":["from pathlib import Path\n","\n","DATA = Path(\"/gdrive/My Drive/columbia_masters/classes/2021_f/genomics/genomics_project\")"],"id":"HMhdxmoNFiJb"},{"cell_type":"code","execution_count":7,"metadata":{"id":"ei38PwRWFiJb","executionInfo":{"status":"ok","timestamp":1639526074924,"user_tz":300,"elapsed":6063,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"outputs":[],"source":["# read data\n","df_raw = pd.read_csv(DATA / 'raw_data.zip', compression = 'zip').drop(columns=['Unnamed: 0'])\n","df_feature = pd.read_csv(DATA / 'feature_data.zip', compression = 'zip').drop(columns=['Unnamed: 0'])\n","df_labels = pd.read_csv(DATA / 'label_data.zip', compression = 'zip').drop(columns=['Unnamed: 0'])"],"id":"ei38PwRWFiJb"},{"cell_type":"code","source":["# save features and labels in a variable\n","df_raw = pd.merge(df_feature, df_labels, on='id')\n","df_raw.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"jr8PAjqS2KNL","executionInfo":{"status":"ok","timestamp":1639526075268,"user_tz":300,"elapsed":356,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"2de2c6f1-afc7-4858-f4e6-a4118e14b331"},"id":"jr8PAjqS2KNL","execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>with_drug</th>\n","      <th>time</th>\n","      <th>dosage</th>\n","      <th>drug</th>\n","      <th>g-0</th>\n","      <th>g-1</th>\n","      <th>g-2</th>\n","      <th>g-3</th>\n","      <th>g-4</th>\n","      <th>g-5</th>\n","      <th>g-6</th>\n","      <th>g-7</th>\n","      <th>g-8</th>\n","      <th>g-9</th>\n","      <th>g-10</th>\n","      <th>g-11</th>\n","      <th>g-12</th>\n","      <th>g-13</th>\n","      <th>g-14</th>\n","      <th>g-15</th>\n","      <th>g-16</th>\n","      <th>g-17</th>\n","      <th>g-18</th>\n","      <th>g-19</th>\n","      <th>g-20</th>\n","      <th>g-21</th>\n","      <th>g-22</th>\n","      <th>g-23</th>\n","      <th>g-24</th>\n","      <th>g-25</th>\n","      <th>g-26</th>\n","      <th>g-27</th>\n","      <th>g-28</th>\n","      <th>g-29</th>\n","      <th>g-30</th>\n","      <th>g-31</th>\n","      <th>g-32</th>\n","      <th>g-33</th>\n","      <th>g-34</th>\n","      <th>...</th>\n","      <th>protein_synthesis_inhibitor</th>\n","      <th>protein_tyrosine_kinase_inhibitor</th>\n","      <th>radiopaque_medium</th>\n","      <th>raf_inhibitor</th>\n","      <th>ras_gtpase_inhibitor</th>\n","      <th>retinoid_receptor_agonist</th>\n","      <th>retinoid_receptor_antagonist</th>\n","      <th>rho_associated_kinase_inhibitor</th>\n","      <th>ribonucleoside_reductase_inhibitor</th>\n","      <th>rna_polymerase_inhibitor</th>\n","      <th>serotonin_receptor_agonist</th>\n","      <th>serotonin_receptor_antagonist</th>\n","      <th>serotonin_reuptake_inhibitor</th>\n","      <th>sigma_receptor_agonist</th>\n","      <th>sigma_receptor_antagonist</th>\n","      <th>smoothened_receptor_antagonist</th>\n","      <th>sodium_channel_inhibitor</th>\n","      <th>sphingosine_receptor_agonist</th>\n","      <th>src_inhibitor</th>\n","      <th>steroid</th>\n","      <th>syk_inhibitor</th>\n","      <th>tachykinin_antagonist</th>\n","      <th>tgf-beta_receptor_inhibitor</th>\n","      <th>thrombin_inhibitor</th>\n","      <th>thymidylate_synthase_inhibitor</th>\n","      <th>tlr_agonist</th>\n","      <th>tlr_antagonist</th>\n","      <th>tnf_inhibitor</th>\n","      <th>topoisomerase_inhibitor</th>\n","      <th>transient_receptor_potential_channel_antagonist</th>\n","      <th>tropomyosin_receptor_kinase_inhibitor</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>b68db1d53</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>-1.0120</td>\n","      <td>-1.0220</td>\n","      <td>-0.0326</td>\n","      <td>0.5548</td>\n","      <td>-0.0921</td>\n","      <td>1.1830</td>\n","      <td>0.1530</td>\n","      <td>0.5574</td>\n","      <td>-0.4015</td>\n","      <td>0.1789</td>\n","      <td>-0.6528</td>\n","      <td>-0.7969</td>\n","      <td>0.6342</td>\n","      <td>0.1778</td>\n","      <td>-0.3694</td>\n","      <td>-0.5688</td>\n","      <td>-1.1360</td>\n","      <td>-1.1880</td>\n","      <td>0.6940</td>\n","      <td>0.4393</td>\n","      <td>0.2664</td>\n","      <td>0.1907</td>\n","      <td>0.1628</td>\n","      <td>-0.2853</td>\n","      <td>0.5819</td>\n","      <td>0.2934</td>\n","      <td>-0.5584</td>\n","      <td>-0.0916</td>\n","      <td>-0.3010</td>\n","      <td>-0.1537</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>df89a8e5a</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>0.5207</td>\n","      <td>0.2341</td>\n","      <td>0.3372</td>\n","      <td>-0.4047</td>\n","      <td>0.8507</td>\n","      <td>-1.1520</td>\n","      <td>-0.4201</td>\n","      <td>-0.0958</td>\n","      <td>0.4590</td>\n","      <td>0.0803</td>\n","      <td>0.2250</td>\n","      <td>0.5293</td>\n","      <td>0.2839</td>\n","      <td>-0.3494</td>\n","      <td>0.2883</td>\n","      <td>0.9449</td>\n","      <td>-0.1646</td>\n","      <td>-0.2657</td>\n","      <td>-0.3372</td>\n","      <td>0.3135</td>\n","      <td>-0.4316</td>\n","      <td>0.4773</td>\n","      <td>0.2075</td>\n","      <td>-0.4216</td>\n","      <td>-0.1161</td>\n","      <td>-0.0499</td>\n","      <td>-0.2627</td>\n","      <td>0.9959</td>\n","      <td>-0.2483</td>\n","      <td>0.2655</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>18bb41b2c</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>1.2390</td>\n","      <td>0.1715</td>\n","      <td>0.2155</td>\n","      <td>0.0065</td>\n","      <td>1.2300</td>\n","      <td>-0.4797</td>\n","      <td>-0.5631</td>\n","      <td>-0.0366</td>\n","      <td>-1.8300</td>\n","      <td>0.6057</td>\n","      <td>-0.3278</td>\n","      <td>0.6042</td>\n","      <td>-0.3075</td>\n","      <td>-0.1147</td>\n","      <td>-0.0570</td>\n","      <td>-0.0799</td>\n","      <td>-0.8181</td>\n","      <td>-1.5320</td>\n","      <td>0.2307</td>\n","      <td>0.4901</td>\n","      <td>0.4780</td>\n","      <td>-1.3970</td>\n","      <td>4.6240</td>\n","      <td>-0.0437</td>\n","      <td>1.2870</td>\n","      <td>-1.8530</td>\n","      <td>0.6069</td>\n","      <td>0.4290</td>\n","      <td>0.1783</td>\n","      <td>0.0018</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>8c7f86626</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>-0.8095</td>\n","      <td>-1.9590</td>\n","      <td>0.1792</td>\n","      <td>-0.1321</td>\n","      <td>-1.0600</td>\n","      <td>-0.8269</td>\n","      <td>-0.3584</td>\n","      <td>-0.8511</td>\n","      <td>-0.5844</td>\n","      <td>-2.5690</td>\n","      <td>0.8183</td>\n","      <td>-0.0532</td>\n","      <td>-0.8554</td>\n","      <td>0.1160</td>\n","      <td>-2.3520</td>\n","      <td>2.1200</td>\n","      <td>-1.1580</td>\n","      <td>-0.7191</td>\n","      <td>-0.8004</td>\n","      <td>-1.4670</td>\n","      <td>-0.0107</td>\n","      <td>-0.8995</td>\n","      <td>0.2406</td>\n","      <td>-0.2479</td>\n","      <td>-1.0890</td>\n","      <td>-0.7575</td>\n","      <td>0.0881</td>\n","      <td>-2.7370</td>\n","      <td>0.8745</td>\n","      <td>0.5787</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>7cbed3131</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>-0.8244</td>\n","      <td>-0.2800</td>\n","      <td>-0.1498</td>\n","      <td>-0.8789</td>\n","      <td>0.8630</td>\n","      <td>-0.2219</td>\n","      <td>-0.5121</td>\n","      <td>-0.9577</td>\n","      <td>1.1750</td>\n","      <td>0.2042</td>\n","      <td>0.1970</td>\n","      <td>0.1244</td>\n","      <td>-1.7090</td>\n","      <td>-0.3543</td>\n","      <td>-0.5160</td>\n","      <td>-0.3330</td>\n","      <td>-0.2685</td>\n","      <td>0.7649</td>\n","      <td>0.2057</td>\n","      <td>1.3720</td>\n","      <td>0.6835</td>\n","      <td>0.8056</td>\n","      <td>-0.3754</td>\n","      <td>-1.2090</td>\n","      <td>0.2965</td>\n","      <td>-0.0712</td>\n","      <td>0.6389</td>\n","      <td>0.6674</td>\n","      <td>-0.0783</td>\n","      <td>1.1740</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1083 columns</p>\n","</div>"],"text/plain":["             id  with_drug  ...  vitamin_d_receptor_agonist wnt_inhibitor\n","0  id_000644bb2       True  ...                           0             0\n","1  id_000779bfc       True  ...                           0             0\n","2  id_000a6266a       True  ...                           0             0\n","3  id_0015fd391       True  ...                           0             0\n","4  id_001626bd3       True  ...                           0             0\n","\n","[5 rows x 1083 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df_labels.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"seiICCf6GmSg","executionInfo":{"status":"ok","timestamp":1639526075467,"user_tz":300,"elapsed":201,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"a2c32651-b972-47d8-bd88-c461b3313d41"},"id":"seiICCf6GmSg","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>5-alpha_reductase_inhibitor</th>\n","      <th>11-beta-hsd1_inhibitor</th>\n","      <th>acat_inhibitor</th>\n","      <th>acetylcholine_receptor_agonist</th>\n","      <th>acetylcholine_receptor_antagonist</th>\n","      <th>acetylcholinesterase_inhibitor</th>\n","      <th>adenosine_receptor_agonist</th>\n","      <th>adenosine_receptor_antagonist</th>\n","      <th>adenylyl_cyclase_activator</th>\n","      <th>adrenergic_receptor_agonist</th>\n","      <th>adrenergic_receptor_antagonist</th>\n","      <th>akt_inhibitor</th>\n","      <th>aldehyde_dehydrogenase_inhibitor</th>\n","      <th>alk_inhibitor</th>\n","      <th>ampk_activator</th>\n","      <th>analgesic</th>\n","      <th>androgen_receptor_agonist</th>\n","      <th>androgen_receptor_antagonist</th>\n","      <th>anesthetic_-_local</th>\n","      <th>angiogenesis_inhibitor</th>\n","      <th>angiotensin_receptor_antagonist</th>\n","      <th>anti-inflammatory</th>\n","      <th>antiarrhythmic</th>\n","      <th>antibiotic</th>\n","      <th>anticonvulsant</th>\n","      <th>antifungal</th>\n","      <th>antihistamine</th>\n","      <th>antimalarial</th>\n","      <th>antioxidant</th>\n","      <th>antiprotozoal</th>\n","      <th>antiviral</th>\n","      <th>apoptosis_stimulant</th>\n","      <th>aromatase_inhibitor</th>\n","      <th>atm_kinase_inhibitor</th>\n","      <th>atp-sensitive_potassium_channel_antagonist</th>\n","      <th>atp_synthase_inhibitor</th>\n","      <th>atpase_inhibitor</th>\n","      <th>atr_kinase_inhibitor</th>\n","      <th>aurora_kinase_inhibitor</th>\n","      <th>...</th>\n","      <th>protein_synthesis_inhibitor</th>\n","      <th>protein_tyrosine_kinase_inhibitor</th>\n","      <th>radiopaque_medium</th>\n","      <th>raf_inhibitor</th>\n","      <th>ras_gtpase_inhibitor</th>\n","      <th>retinoid_receptor_agonist</th>\n","      <th>retinoid_receptor_antagonist</th>\n","      <th>rho_associated_kinase_inhibitor</th>\n","      <th>ribonucleoside_reductase_inhibitor</th>\n","      <th>rna_polymerase_inhibitor</th>\n","      <th>serotonin_receptor_agonist</th>\n","      <th>serotonin_receptor_antagonist</th>\n","      <th>serotonin_reuptake_inhibitor</th>\n","      <th>sigma_receptor_agonist</th>\n","      <th>sigma_receptor_antagonist</th>\n","      <th>smoothened_receptor_antagonist</th>\n","      <th>sodium_channel_inhibitor</th>\n","      <th>sphingosine_receptor_agonist</th>\n","      <th>src_inhibitor</th>\n","      <th>steroid</th>\n","      <th>syk_inhibitor</th>\n","      <th>tachykinin_antagonist</th>\n","      <th>tgf-beta_receptor_inhibitor</th>\n","      <th>thrombin_inhibitor</th>\n","      <th>thymidylate_synthase_inhibitor</th>\n","      <th>tlr_agonist</th>\n","      <th>tlr_antagonist</th>\n","      <th>tnf_inhibitor</th>\n","      <th>topoisomerase_inhibitor</th>\n","      <th>transient_receptor_potential_channel_antagonist</th>\n","      <th>tropomyosin_receptor_kinase_inhibitor</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 207 columns</p>\n","</div>"],"text/plain":["             id  ...  wnt_inhibitor\n","0  id_000644bb2  ...              0\n","1  id_000779bfc  ...              0\n","2  id_000a6266a  ...              0\n","3  id_0015fd391  ...              0\n","4  id_001626bd3  ...              0\n","\n","[5 rows x 207 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df_feature.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"id":"AvsrNqILF7qX","executionInfo":{"status":"ok","timestamp":1639526075468,"user_tz":300,"elapsed":13,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"40071109-1bed-4806-c338-f99cc8b7b3bf"},"id":"AvsrNqILF7qX","execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>with_drug</th>\n","      <th>time</th>\n","      <th>dosage</th>\n","      <th>drug</th>\n","      <th>g-0</th>\n","      <th>g-1</th>\n","      <th>g-2</th>\n","      <th>g-3</th>\n","      <th>g-4</th>\n","      <th>g-5</th>\n","      <th>g-6</th>\n","      <th>g-7</th>\n","      <th>g-8</th>\n","      <th>g-9</th>\n","      <th>g-10</th>\n","      <th>g-11</th>\n","      <th>g-12</th>\n","      <th>g-13</th>\n","      <th>g-14</th>\n","      <th>g-15</th>\n","      <th>g-16</th>\n","      <th>g-17</th>\n","      <th>g-18</th>\n","      <th>g-19</th>\n","      <th>g-20</th>\n","      <th>g-21</th>\n","      <th>g-22</th>\n","      <th>g-23</th>\n","      <th>g-24</th>\n","      <th>g-25</th>\n","      <th>g-26</th>\n","      <th>g-27</th>\n","      <th>g-28</th>\n","      <th>g-29</th>\n","      <th>g-30</th>\n","      <th>g-31</th>\n","      <th>g-32</th>\n","      <th>g-33</th>\n","      <th>g-34</th>\n","      <th>...</th>\n","      <th>c-60</th>\n","      <th>c-61</th>\n","      <th>c-62</th>\n","      <th>c-63</th>\n","      <th>c-64</th>\n","      <th>c-65</th>\n","      <th>c-66</th>\n","      <th>c-67</th>\n","      <th>c-68</th>\n","      <th>c-69</th>\n","      <th>c-70</th>\n","      <th>c-71</th>\n","      <th>c-72</th>\n","      <th>c-73</th>\n","      <th>c-74</th>\n","      <th>c-75</th>\n","      <th>c-76</th>\n","      <th>c-77</th>\n","      <th>c-78</th>\n","      <th>c-79</th>\n","      <th>c-80</th>\n","      <th>c-81</th>\n","      <th>c-82</th>\n","      <th>c-83</th>\n","      <th>c-84</th>\n","      <th>c-85</th>\n","      <th>c-86</th>\n","      <th>c-87</th>\n","      <th>c-88</th>\n","      <th>c-89</th>\n","      <th>c-90</th>\n","      <th>c-91</th>\n","      <th>c-92</th>\n","      <th>c-93</th>\n","      <th>c-94</th>\n","      <th>c-95</th>\n","      <th>c-96</th>\n","      <th>c-97</th>\n","      <th>c-98</th>\n","      <th>c-99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>b68db1d53</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>-1.0120</td>\n","      <td>-1.0220</td>\n","      <td>-0.0326</td>\n","      <td>0.5548</td>\n","      <td>-0.0921</td>\n","      <td>1.1830</td>\n","      <td>0.1530</td>\n","      <td>0.5574</td>\n","      <td>-0.4015</td>\n","      <td>0.1789</td>\n","      <td>-0.6528</td>\n","      <td>-0.7969</td>\n","      <td>0.6342</td>\n","      <td>0.1778</td>\n","      <td>-0.3694</td>\n","      <td>-0.5688</td>\n","      <td>-1.1360</td>\n","      <td>-1.1880</td>\n","      <td>0.6940</td>\n","      <td>0.4393</td>\n","      <td>0.2664</td>\n","      <td>0.1907</td>\n","      <td>0.1628</td>\n","      <td>-0.2853</td>\n","      <td>0.5819</td>\n","      <td>0.2934</td>\n","      <td>-0.5584</td>\n","      <td>-0.0916</td>\n","      <td>-0.3010</td>\n","      <td>-0.1537</td>\n","      <td>...</td>\n","      <td>0.4805</td>\n","      <td>0.4965</td>\n","      <td>0.3680</td>\n","      <td>0.8427</td>\n","      <td>0.1042</td>\n","      <td>0.1403</td>\n","      <td>0.1758</td>\n","      <td>1.2570</td>\n","      <td>-0.5979</td>\n","      <td>1.2250</td>\n","      <td>-0.0553</td>\n","      <td>0.7351</td>\n","      <td>0.5810</td>\n","      <td>0.9590</td>\n","      <td>0.2427</td>\n","      <td>0.0495</td>\n","      <td>0.4141</td>\n","      <td>0.8432</td>\n","      <td>0.6162</td>\n","      <td>-0.7318</td>\n","      <td>1.2120</td>\n","      <td>0.6362</td>\n","      <td>-0.4427</td>\n","      <td>0.1288</td>\n","      <td>1.4840</td>\n","      <td>0.1799</td>\n","      <td>0.5367</td>\n","      <td>-0.1111</td>\n","      <td>-1.0120</td>\n","      <td>0.6685</td>\n","      <td>0.2862</td>\n","      <td>0.2584</td>\n","      <td>0.8076</td>\n","      <td>0.5523</td>\n","      <td>-0.1912</td>\n","      <td>0.6584</td>\n","      <td>-0.3981</td>\n","      <td>0.2139</td>\n","      <td>0.3801</td>\n","      <td>0.4176</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>df89a8e5a</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>0.5207</td>\n","      <td>0.2341</td>\n","      <td>0.3372</td>\n","      <td>-0.4047</td>\n","      <td>0.8507</td>\n","      <td>-1.1520</td>\n","      <td>-0.4201</td>\n","      <td>-0.0958</td>\n","      <td>0.4590</td>\n","      <td>0.0803</td>\n","      <td>0.2250</td>\n","      <td>0.5293</td>\n","      <td>0.2839</td>\n","      <td>-0.3494</td>\n","      <td>0.2883</td>\n","      <td>0.9449</td>\n","      <td>-0.1646</td>\n","      <td>-0.2657</td>\n","      <td>-0.3372</td>\n","      <td>0.3135</td>\n","      <td>-0.4316</td>\n","      <td>0.4773</td>\n","      <td>0.2075</td>\n","      <td>-0.4216</td>\n","      <td>-0.1161</td>\n","      <td>-0.0499</td>\n","      <td>-0.2627</td>\n","      <td>0.9959</td>\n","      <td>-0.2483</td>\n","      <td>0.2655</td>\n","      <td>...</td>\n","      <td>0.4083</td>\n","      <td>0.0319</td>\n","      <td>0.3905</td>\n","      <td>0.7099</td>\n","      <td>0.2912</td>\n","      <td>0.4151</td>\n","      <td>-0.2840</td>\n","      <td>-0.3104</td>\n","      <td>-0.6373</td>\n","      <td>0.2887</td>\n","      <td>-0.0765</td>\n","      <td>0.2539</td>\n","      <td>0.4443</td>\n","      <td>0.5932</td>\n","      <td>0.2031</td>\n","      <td>0.7639</td>\n","      <td>0.5499</td>\n","      <td>-0.3322</td>\n","      <td>-0.0977</td>\n","      <td>0.4329</td>\n","      <td>-0.2782</td>\n","      <td>0.7827</td>\n","      <td>0.5934</td>\n","      <td>0.3402</td>\n","      <td>0.1499</td>\n","      <td>0.4420</td>\n","      <td>0.9366</td>\n","      <td>0.8193</td>\n","      <td>-0.4236</td>\n","      <td>0.3192</td>\n","      <td>-0.4265</td>\n","      <td>0.7543</td>\n","      <td>0.4708</td>\n","      <td>0.0230</td>\n","      <td>0.2957</td>\n","      <td>0.4899</td>\n","      <td>0.1522</td>\n","      <td>0.1241</td>\n","      <td>0.6077</td>\n","      <td>0.7371</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>18bb41b2c</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>1.2390</td>\n","      <td>0.1715</td>\n","      <td>0.2155</td>\n","      <td>0.0065</td>\n","      <td>1.2300</td>\n","      <td>-0.4797</td>\n","      <td>-0.5631</td>\n","      <td>-0.0366</td>\n","      <td>-1.8300</td>\n","      <td>0.6057</td>\n","      <td>-0.3278</td>\n","      <td>0.6042</td>\n","      <td>-0.3075</td>\n","      <td>-0.1147</td>\n","      <td>-0.0570</td>\n","      <td>-0.0799</td>\n","      <td>-0.8181</td>\n","      <td>-1.5320</td>\n","      <td>0.2307</td>\n","      <td>0.4901</td>\n","      <td>0.4780</td>\n","      <td>-1.3970</td>\n","      <td>4.6240</td>\n","      <td>-0.0437</td>\n","      <td>1.2870</td>\n","      <td>-1.8530</td>\n","      <td>0.6069</td>\n","      <td>0.4290</td>\n","      <td>0.1783</td>\n","      <td>0.0018</td>\n","      <td>...</td>\n","      <td>-0.5477</td>\n","      <td>-0.7576</td>\n","      <td>-0.0444</td>\n","      <td>0.1894</td>\n","      <td>-0.0014</td>\n","      <td>-2.3640</td>\n","      <td>-0.4682</td>\n","      <td>0.1210</td>\n","      <td>-0.5177</td>\n","      <td>-0.0604</td>\n","      <td>0.1682</td>\n","      <td>-0.4436</td>\n","      <td>0.4963</td>\n","      <td>0.1363</td>\n","      <td>0.3335</td>\n","      <td>0.9760</td>\n","      <td>-0.0427</td>\n","      <td>-0.1235</td>\n","      <td>0.0959</td>\n","      <td>0.0690</td>\n","      <td>-0.9416</td>\n","      <td>-0.7548</td>\n","      <td>-0.1109</td>\n","      <td>-0.6272</td>\n","      <td>0.3019</td>\n","      <td>0.1172</td>\n","      <td>0.1093</td>\n","      <td>-0.3113</td>\n","      <td>0.3019</td>\n","      <td>-0.0873</td>\n","      <td>-0.7250</td>\n","      <td>-0.6297</td>\n","      <td>0.6103</td>\n","      <td>0.0223</td>\n","      <td>-1.3240</td>\n","      <td>-0.3174</td>\n","      <td>-0.6417</td>\n","      <td>-0.2187</td>\n","      <td>-1.4080</td>\n","      <td>0.6931</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>8c7f86626</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>-0.8095</td>\n","      <td>-1.9590</td>\n","      <td>0.1792</td>\n","      <td>-0.1321</td>\n","      <td>-1.0600</td>\n","      <td>-0.8269</td>\n","      <td>-0.3584</td>\n","      <td>-0.8511</td>\n","      <td>-0.5844</td>\n","      <td>-2.5690</td>\n","      <td>0.8183</td>\n","      <td>-0.0532</td>\n","      <td>-0.8554</td>\n","      <td>0.1160</td>\n","      <td>-2.3520</td>\n","      <td>2.1200</td>\n","      <td>-1.1580</td>\n","      <td>-0.7191</td>\n","      <td>-0.8004</td>\n","      <td>-1.4670</td>\n","      <td>-0.0107</td>\n","      <td>-0.8995</td>\n","      <td>0.2406</td>\n","      <td>-0.2479</td>\n","      <td>-1.0890</td>\n","      <td>-0.7575</td>\n","      <td>0.0881</td>\n","      <td>-2.7370</td>\n","      <td>0.8745</td>\n","      <td>0.5787</td>\n","      <td>...</td>\n","      <td>-2.1220</td>\n","      <td>-0.3752</td>\n","      <td>-2.3820</td>\n","      <td>-3.7350</td>\n","      <td>-2.9740</td>\n","      <td>-1.4930</td>\n","      <td>-1.6600</td>\n","      <td>-3.1660</td>\n","      <td>0.2816</td>\n","      <td>-0.2990</td>\n","      <td>-1.1870</td>\n","      <td>-0.5044</td>\n","      <td>-1.7750</td>\n","      <td>-1.6120</td>\n","      <td>-0.9215</td>\n","      <td>-1.0810</td>\n","      <td>-3.0520</td>\n","      <td>-3.4470</td>\n","      <td>-2.7740</td>\n","      <td>-1.8460</td>\n","      <td>-0.5568</td>\n","      <td>-3.3960</td>\n","      <td>-2.9510</td>\n","      <td>-1.1550</td>\n","      <td>-3.2620</td>\n","      <td>-1.5390</td>\n","      <td>-2.4600</td>\n","      <td>-0.9417</td>\n","      <td>-1.5550</td>\n","      <td>0.2431</td>\n","      <td>-2.0990</td>\n","      <td>-0.6441</td>\n","      <td>-5.6300</td>\n","      <td>-1.3780</td>\n","      <td>-0.8632</td>\n","      <td>-1.2880</td>\n","      <td>-1.6210</td>\n","      <td>-0.8784</td>\n","      <td>-0.3876</td>\n","      <td>-0.8154</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>7cbed3131</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>-0.8244</td>\n","      <td>-0.2800</td>\n","      <td>-0.1498</td>\n","      <td>-0.8789</td>\n","      <td>0.8630</td>\n","      <td>-0.2219</td>\n","      <td>-0.5121</td>\n","      <td>-0.9577</td>\n","      <td>1.1750</td>\n","      <td>0.2042</td>\n","      <td>0.1970</td>\n","      <td>0.1244</td>\n","      <td>-1.7090</td>\n","      <td>-0.3543</td>\n","      <td>-0.5160</td>\n","      <td>-0.3330</td>\n","      <td>-0.2685</td>\n","      <td>0.7649</td>\n","      <td>0.2057</td>\n","      <td>1.3720</td>\n","      <td>0.6835</td>\n","      <td>0.8056</td>\n","      <td>-0.3754</td>\n","      <td>-1.2090</td>\n","      <td>0.2965</td>\n","      <td>-0.0712</td>\n","      <td>0.6389</td>\n","      <td>0.6674</td>\n","      <td>-0.0783</td>\n","      <td>1.1740</td>\n","      <td>...</td>\n","      <td>-0.2274</td>\n","      <td>0.3215</td>\n","      <td>0.1535</td>\n","      <td>-0.4640</td>\n","      <td>-0.5943</td>\n","      <td>0.3973</td>\n","      <td>0.1500</td>\n","      <td>0.5178</td>\n","      <td>0.5159</td>\n","      <td>0.6091</td>\n","      <td>0.1813</td>\n","      <td>-0.4249</td>\n","      <td>0.7832</td>\n","      <td>0.6529</td>\n","      <td>0.5648</td>\n","      <td>0.4817</td>\n","      <td>0.0587</td>\n","      <td>0.5303</td>\n","      <td>0.6376</td>\n","      <td>-0.3966</td>\n","      <td>-1.4950</td>\n","      <td>-0.9625</td>\n","      <td>-0.0541</td>\n","      <td>0.6273</td>\n","      <td>0.4563</td>\n","      <td>0.0698</td>\n","      <td>0.8134</td>\n","      <td>0.1924</td>\n","      <td>0.6054</td>\n","      <td>-0.1824</td>\n","      <td>0.0042</td>\n","      <td>0.0048</td>\n","      <td>0.6670</td>\n","      <td>1.0690</td>\n","      <td>0.5523</td>\n","      <td>-0.3031</td>\n","      <td>0.1094</td>\n","      <td>0.2885</td>\n","      <td>-0.3786</td>\n","      <td>0.7125</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 877 columns</p>\n","</div>"],"text/plain":["             id  with_drug  time dosage  ...    c-96    c-97    c-98    c-99\n","0  id_000644bb2       True    24     D1  ... -0.3981  0.2139  0.3801  0.4176\n","1  id_000779bfc       True    72     D1  ...  0.1522  0.1241  0.6077  0.7371\n","2  id_000a6266a       True    48     D1  ... -0.6417 -0.2187 -1.4080  0.6931\n","3  id_0015fd391       True    48     D1  ... -1.6210 -0.8784 -0.3876 -0.8154\n","4  id_001626bd3       True    72     D2  ...  0.1094  0.2885 -0.3786  0.7125\n","\n","[5 rows x 877 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df_raw['n_moa'] = df_labels.drop('id', axis=1).sum(axis=1)\n","plt.hist(df_raw['n_moa'])\n","plt.title = 'Number of occurences by number of moa'\n","plt.xlabel('Number of moa')\n","plt.ylabel('Number of occurences')\n","\n","plt.grid(True)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"Q5s_vViI3e9A","executionInfo":{"status":"ok","timestamp":1639526075585,"user_tz":300,"elapsed":127,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"fd1e4c6e-aa73-485e-b5ed-5396126b3252"},"id":"Q5s_vViI3e9A","execution_count":11,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["labels_count = df_labels.drop(columns='id').sum(axis=0)\n","plt.hist(labels_count)\n","plt.xlabel('Number of occurences')\n","plt.ylabel('Number of labels')\n","plt.title = 'Number of labels by number of occurences'\n","plt.grid(True)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"nBAliP83GyhD","executionInfo":{"status":"ok","timestamp":1639526076028,"user_tz":300,"elapsed":445,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"307a71d3-3d2d-42f4-ea80-36c7f9bbe708"},"id":"nBAliP83GyhD","execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# check how many occurences of each label\n","np.unique(labels_count, return_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORskRAgr7Vg5","executionInfo":{"status":"ok","timestamp":1639526076029,"user_tz":300,"elapsed":5,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"eb5fb85b-8601-4b36-c037-8564ba11a641"},"id":"ORskRAgr7Vg5","execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([  1,   6,   7,  12,  13,  17,  18,  19,  23,  24,  25,  26,  29,\n","         30,  31,  32,  35,  36,  37,  38,  39,  42,  43,  44,  47,  48,\n","         49,  50,  51,  54,  55,  56,  59,  60,  61,  62,  66,  67,  68,\n","         71,  72,  73,  74,  80,  84,  85,  89,  92,  93,  96,  97,  98,\n","        102, 103, 104, 106, 115, 119, 121, 127, 130, 151, 158, 165, 170,\n","        190, 192, 223, 236, 241, 264, 266, 267, 270, 273, 279, 281, 283,\n","        297, 301, 316, 336, 340, 360, 367, 402, 404, 424, 435, 726, 832]),\n"," array([ 2, 16,  4, 11,  2,  1, 13,  4,  2,  5,  8,  3,  1,  6,  4,  1,  1,\n","        12,  6,  1,  1,  4,  1,  1,  1,  7,  1,  1,  1,  3,  2,  2,  1,  3,\n","         3,  2,  1,  2,  1,  1,  3,  5,  2,  2,  1,  1,  2,  1,  1,  3,  1,\n","         1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1]))"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["Remove columns (labels) with less than 15 occurences"],"metadata":{"id":"f7ZIuvlYBISu"},"id":"f7ZIuvlYBISu"},{"cell_type":"code","source":["labels_count = df_labels.drop(columns='id').sum(axis=0)\n","# minimum label occurences\n","min_label_occur = 100\n","# we need to add one because we need to count the id column\n","drop_labels = list(labels_count[(labels_count<min_label_occur)].index)\n","drop_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGsyvyw_8hw0","executionInfo":{"status":"ok","timestamp":1639526076140,"user_tz":300,"elapsed":115,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"ad47e1a8-67de-47e7-a8c5-2997a276011a"},"id":"AGsyvyw_8hw0","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['5-alpha_reductase_inhibitor',\n"," '11-beta-hsd1_inhibitor',\n"," 'acat_inhibitor',\n"," 'acetylcholinesterase_inhibitor',\n"," 'adenosine_receptor_agonist',\n"," 'adenosine_receptor_antagonist',\n"," 'adenylyl_cyclase_activator',\n"," 'akt_inhibitor',\n"," 'aldehyde_dehydrogenase_inhibitor',\n"," 'alk_inhibitor',\n"," 'ampk_activator',\n"," 'analgesic',\n"," 'androgen_receptor_agonist',\n"," 'androgen_receptor_antagonist',\n"," 'anesthetic_-_local',\n"," 'angiogenesis_inhibitor',\n"," 'angiotensin_receptor_antagonist',\n"," 'anti-inflammatory',\n"," 'antiarrhythmic',\n"," 'antibiotic',\n"," 'anticonvulsant',\n"," 'antifungal',\n"," 'antihistamine',\n"," 'antimalarial',\n"," 'antioxidant',\n"," 'antiprotozoal',\n"," 'antiviral',\n"," 'apoptosis_stimulant',\n"," 'aromatase_inhibitor',\n"," 'atm_kinase_inhibitor',\n"," 'atp-sensitive_potassium_channel_antagonist',\n"," 'atp_synthase_inhibitor',\n"," 'atpase_inhibitor',\n"," 'atr_kinase_inhibitor',\n"," 'aurora_kinase_inhibitor',\n"," 'autotaxin_inhibitor',\n"," 'bacterial_30s_ribosomal_subunit_inhibitor',\n"," 'bacterial_50s_ribosomal_subunit_inhibitor',\n"," 'bacterial_antifolate',\n"," 'bacterial_dna_gyrase_inhibitor',\n"," 'bacterial_membrane_integrity_inhibitor',\n"," 'bcl_inhibitor',\n"," 'bcr-abl_inhibitor',\n"," 'benzodiazepine_receptor_agonist',\n"," 'beta_amyloid_inhibitor',\n"," 'bromodomain_inhibitor',\n"," 'btk_inhibitor',\n"," 'calcineurin_inhibitor',\n"," 'cannabinoid_receptor_agonist',\n"," 'cannabinoid_receptor_antagonist',\n"," 'carbonic_anhydrase_inhibitor',\n"," 'casein_kinase_inhibitor',\n"," 'caspase_activator',\n"," 'catechol_o_methyltransferase_inhibitor',\n"," 'cck_receptor_antagonist',\n"," 'chelating_agent',\n"," 'chk_inhibitor',\n"," 'chloride_channel_blocker',\n"," 'cholesterol_inhibitor',\n"," 'cholinergic_receptor_antagonist',\n"," 'coagulation_factor_inhibitor',\n"," 'corticosteroid_agonist',\n"," 'dihydrofolate_reductase_inhibitor',\n"," 'dipeptidyl_peptidase_inhibitor',\n"," 'diuretic',\n"," 'dna_alkylating_agent',\n"," 'elastase_inhibitor',\n"," 'erbb2_inhibitor',\n"," 'estrogen_receptor_antagonist',\n"," 'faah_inhibitor',\n"," 'farnesyltransferase_inhibitor',\n"," 'fatty_acid_receptor_agonist',\n"," 'fgfr_inhibitor',\n"," 'focal_adhesion_kinase_inhibitor',\n"," 'free_radical_scavenger',\n"," 'fungal_squalene_epoxidase_inhibitor',\n"," 'gamma_secretase_inhibitor',\n"," 'glutamate_inhibitor',\n"," 'glutamate_receptor_agonist',\n"," 'gonadotropin_receptor_agonist',\n"," 'gsk_inhibitor',\n"," 'hcv_inhibitor',\n"," 'histamine_receptor_agonist',\n"," 'histone_lysine_demethylase_inhibitor',\n"," 'histone_lysine_methyltransferase_inhibitor',\n"," 'hiv_inhibitor',\n"," 'hsp_inhibitor',\n"," 'igf-1_inhibitor',\n"," 'ikk_inhibitor',\n"," 'imidazoline_receptor_agonist',\n"," 'immunosuppressant',\n"," 'insulin_secretagogue',\n"," 'insulin_sensitizer',\n"," 'integrin_inhibitor',\n"," 'jak_inhibitor',\n"," 'laxative',\n"," 'leukotriene_inhibitor',\n"," 'leukotriene_receptor_antagonist',\n"," 'lipase_inhibitor',\n"," 'lipoxygenase_inhibitor',\n"," 'lxr_agonist',\n"," 'mdm_inhibitor',\n"," 'mek_inhibitor',\n"," 'membrane_integrity_inhibitor',\n"," 'mineralocorticoid_receptor_antagonist',\n"," 'monoacylglycerol_lipase_inhibitor',\n"," 'monoamine_oxidase_inhibitor',\n"," 'monopolar_spindle_1_kinase_inhibitor',\n"," 'mucolytic_agent',\n"," 'neuropeptide_receptor_antagonist',\n"," 'nicotinic_receptor_agonist',\n"," 'nitric_oxide_donor',\n"," 'nitric_oxide_production_inhibitor',\n"," 'nitric_oxide_synthase_inhibitor',\n"," 'norepinephrine_reuptake_inhibitor',\n"," 'nrf2_activator',\n"," 'opioid_receptor_agonist',\n"," 'opioid_receptor_antagonist',\n"," 'orexin_receptor_antagonist',\n"," 'p38_mapk_inhibitor',\n"," 'p-glycoprotein_inhibitor',\n"," 'parp_inhibitor',\n"," 'pdk_inhibitor',\n"," 'phospholipase_inhibitor',\n"," 'pkc_inhibitor',\n"," 'potassium_channel_activator',\n"," 'potassium_channel_antagonist',\n"," 'ppar_receptor_antagonist',\n"," 'progesterone_receptor_antagonist',\n"," 'prostaglandin_inhibitor',\n"," 'prostanoid_receptor_antagonist',\n"," 'protein_kinase_inhibitor',\n"," 'protein_phosphatase_inhibitor',\n"," 'protein_tyrosine_kinase_inhibitor',\n"," 'radiopaque_medium',\n"," 'ras_gtpase_inhibitor',\n"," 'retinoid_receptor_agonist',\n"," 'retinoid_receptor_antagonist',\n"," 'rho_associated_kinase_inhibitor',\n"," 'ribonucleoside_reductase_inhibitor',\n"," 'rna_polymerase_inhibitor',\n"," 'serotonin_reuptake_inhibitor',\n"," 'sigma_receptor_agonist',\n"," 'sigma_receptor_antagonist',\n"," 'smoothened_receptor_antagonist',\n"," 'sphingosine_receptor_agonist',\n"," 'src_inhibitor',\n"," 'steroid',\n"," 'syk_inhibitor',\n"," 'tachykinin_antagonist',\n"," 'tgf-beta_receptor_inhibitor',\n"," 'thrombin_inhibitor',\n"," 'thymidylate_synthase_inhibitor',\n"," 'tlr_agonist',\n"," 'tlr_antagonist',\n"," 'tnf_inhibitor',\n"," 'transient_receptor_potential_channel_antagonist',\n"," 'tropomyosin_receptor_kinase_inhibitor',\n"," 'trpv_agonist',\n"," 'trpv_antagonist',\n"," 'tyrosine_kinase_inhibitor',\n"," 'ubiquitin_specific_protease_inhibitor',\n"," 'vitamin_b',\n"," 'vitamin_d_receptor_agonist',\n"," 'wnt_inhibitor']"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# drop on dataset\n","sel_raw = df_raw.drop(columns=drop_labels)\n","sel_labels = df_labels.drop(columns=drop_labels)\n","\n","# re-calculate n_moa\n","sel_raw['n_moa'] = sel_labels.drop('id', axis=1).sum(axis=1)\n","plt.hist(sel_raw['n_moa'])\n","plt.title = 'Number of occurences by number of moa'\n","plt.xlabel('Number of moa')\n","plt.ylabel('Number of occurences')\n","\n","plt.grid(True)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"L4bKFIMj-vkp","executionInfo":{"status":"ok","timestamp":1639526081246,"user_tz":300,"elapsed":411,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"2af7f728-e1ad-4d78-f542-3624053b36ea"},"id":"L4bKFIMj-vkp","execution_count":15,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Remove rows (samples) with:\n","* `n_moa > 1`\n","* `n_moa!= 1`"],"metadata":{"id":"D6VDZM7WBLEF"},"id":"D6VDZM7WBLEF"},{"cell_type":"code","source":["# keep only rows with one or less moa\n","zon_moa_idx = np.where(sel_raw['n_moa']>1)[0]\n","zon_moa_feature = df_feature.drop(index=zon_moa_idx).reset_index(drop=True)\n","zon_moa_labels = sel_labels.drop(index=zon_moa_idx).reset_index(drop=True)\n","# keep only rows with one moa\n","one_moa_idx = np.where(sel_raw['n_moa']!=1)[0]\n","one_moa_feature = df_feature.drop(index=one_moa_idx).reset_index(drop=True)\n","one_moa_labels = sel_labels.drop(index=one_moa_idx).reset_index(drop=True)"],"metadata":{"id":"uex_IrxI3uUS","executionInfo":{"status":"ok","timestamp":1639526086871,"user_tz":300,"elapsed":301,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"uex_IrxI3uUS","execution_count":16,"outputs":[]},{"cell_type":"code","source":["print(f'All n moa shapes {(df_feature.shape, df_labels.shape)}')\n","print(f'One or less moa only shapes {(zon_moa_feature.shape, zon_moa_labels.shape)}')\n","print(f'One moa only shapes {(one_moa_feature.shape, one_moa_labels.shape)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWBWfL9t40In","executionInfo":{"status":"ok","timestamp":1639526090822,"user_tz":300,"elapsed":108,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"e89aa2d3-b982-4b8c-d23f-d70591645b32"},"id":"NWBWfL9t40In","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["All n moa shapes ((23814, 877), (23814, 207))\n","One or less moa only shapes ((22449, 877), (22449, 42))\n","One moa only shapes ((7694, 877), (7694, 42))\n"]}]},{"cell_type":"markdown","source":["Separate Training and testing (and validation) data"],"metadata":{"id":"tbZSofPd0gdT"},"id":"tbZSofPd0gdT"},{"cell_type":"code","source":["# get train set\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n","print(sss)\n","one_moa_feature['dtype'] = 'test'\n","one_moa_labels['dtype'] = 'test'\n","for train_index, test_index in sss.split(one_moa_feature.drop(columns=['id']), one_moa_labels.drop(columns=['id'])):\n","  one_moa_feature.iloc[train_index, -1] = 'train'\n","  one_moa_labels.iloc[train_index, -1] = 'train'\n","  one_moa_feature.iloc[test_index, -1] = 'test'\n","  one_moa_labels.iloc[test_index, -1] = 'test'\n","\n","# get test and validation sets\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.7, random_state=42)\n","print(sss)\n","for val_index, test_index in sss.split(one_moa_feature.drop(columns=['id'])[one_moa_feature['dtype'] == 'test'], one_moa_labels.drop(columns=['id'])[one_moa_labels['dtype'] == 'test']):\n","  one_moa_feature.iloc[val_index, -1] = 'val'\n","  one_moa_labels.iloc[val_index, -1] = 'val'\n","  one_moa_feature.iloc[test_index, -1] = 'test'\n","  one_moa_labels.iloc[test_index, -1] = 'test'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LeFfy4gBxJe","executionInfo":{"status":"ok","timestamp":1639526100285,"user_tz":300,"elapsed":442,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"29593cd4-1ec9-4743-e91e-91fa61514ff3"},"id":"9LeFfy4gBxJe","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["StratifiedShuffleSplit(n_splits=1, random_state=42, test_size=0.3,\n","            train_size=None)\n","StratifiedShuffleSplit(n_splits=1, random_state=42, test_size=0.7,\n","            train_size=None)\n"]}]},{"cell_type":"code","source":["one_moa_labels['dtype'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"di4MzZXmDmCg","executionInfo":{"status":"ok","timestamp":1639526103299,"user_tz":300,"elapsed":115,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"0877746a-6222-4de8-9f39-556cf8fc7936"},"id":"di4MzZXmDmCg","execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["train    3758\n","test     3244\n","val       692\n","Name: dtype, dtype: int64"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["train_labels = one_moa_labels[one_moa_labels.iloc[:, -1] == 'train'].drop(columns=['id', 'dtype']).to_numpy()\n","train_labels = np.argmax(train_labels, axis=1)\n","# train_labels = keras.utils.to_categorical(\n","#     train_labels, dtype='int32'\n","# )\n","# train_labels = np.reshape(train_labels, (train_labels.shape[0], train_labels.shape[1], 1)).astype('float')\n","\n","test_labels = one_moa_labels[one_moa_labels.iloc[:, -1] == 'test'].drop(columns=['id', 'dtype']).to_numpy()\n","test_labels = np.argmax(test_labels, axis=1)\n","# test_labels = keras.utils.to_categorical(\n","#     test_labels, dtype='int32'\n","# )\n","# test_labels = np.reshape(test_labels, (test_labels.shape[0], test_labels.shape[1], 1)).astype('float')\n","\n","val_labels = one_moa_labels[one_moa_labels.iloc[:, -1] == 'val'].drop(columns=['id', 'dtype']).to_numpy()\n","val_labels = np.argmax(val_labels, axis=1)\n","# val_labels = keras.utils.to_categorical(\n","#     val_labels, dtype='int32'\n","# )\n","# val_labels = np.reshape(val_labels, (val_labels.shape[0], val_labels.shape[1], 1)).astype('float')\n","\n","# np.expand_dims(train_features[:,:-1], axis = 2)\n","\n","train_features = one_moa_feature[one_moa_feature.iloc[:, -1] == 'train'].drop(columns=['id', 'dtype']).reset_index(drop=True)\n","temp = pd.get_dummies(train_features)\n","drug_cols = [col for col in temp.columns if col.startswith('drug_')]\n","drug_int = (temp[drug_cols].idxmax(axis=0))-min(temp[drug_cols].idxmax(axis=0))\n","train_features['drug'] = drug_int.reset_index(drop=True).astype(int)\n","train_features['with_drug'] = train_features['with_drug'].astype(int)\n","train_features.loc[np.where(train_features.dosage=='D1')[0],'dosage']=0\n","train_features.loc[np.where(train_features.dosage=='D2')[0],'dosage']=1\n","# train_features = np.expand_dims(train_features.to_numpy(), axis = 2)\n","\n","test_features = one_moa_feature[one_moa_feature.iloc[:, -1] == 'test'].drop(columns=['id', 'dtype']).reset_index(drop=True)\n","temp = pd.get_dummies(test_features)\n","drug_cols = [col for col in temp.columns if col.startswith('drug_')]\n","drug_int = (temp[drug_cols].idxmax(axis=0))-min(temp[drug_cols].idxmax(axis=0))\n","test_features['drug'] = drug_int.reset_index(drop=True).astype(int)\n","test_features.loc[np.where(test_features.dosage=='D1')[0], 'dosage']=0\n","test_features.loc[np.where(test_features.dosage=='D2')[0], 'dosage']=1\n","test_features['with_drug'] = test_features['with_drug'].astype(int)\n","# test_features = np.expand_dims(test_features.to_numpy(), axis = 2)\n","\n","val_features = one_moa_feature[one_moa_feature.iloc[:, -1] == 'val'].drop(columns=['id', 'dtype']).reset_index(drop=True)\n","temp = pd.get_dummies(val_features)\n","drug_cols = [col for col in temp.columns if col.startswith('drug_')]\n","drug_int = (temp[drug_cols].idxmax(axis=0))-min(temp[drug_cols].idxmax(axis=0))\n","val_features['drug'] = drug_int.reset_index(drop=True).astype(int)\n","val_features.loc[np.where(val_features.dosage=='D1')[0], 'dosage']=0\n","val_features.loc[np.where(val_features.dosage=='D2')[0], 'dosage']=1\n","val_features['with_drug'] = val_features['with_drug'].astype(int)\n","# val_features = np.expand_dims(val_features.to_numpy(), axis = 2)"],"metadata":{"id":"p1CD_yWHzsyH","executionInfo":{"status":"ok","timestamp":1639526106352,"user_tz":300,"elapsed":398,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"p1CD_yWHzsyH","execution_count":20,"outputs":[]},{"cell_type":"code","source":["# train_features = one_moa_feature[one_moa_feature.iloc[:, -1] == 'train'].drop(columns=['id', 'dtype']).reset_index(drop=True)\n","# temp = pd.get_dummies(train_features)\n","# drug_cols = [col for col in temp.columns if col.startswith('drug_')]\n","# drug_col = (temp[drug_cols].idxmax(axis=0))-min(temp[drug_cols].idxmax(axis=0))\n","# train_features['drug'] = drug_col.reset_index(drop=True).astype(int)\n","# train_features.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"id":"4Qsi4jKR7lMF","executionInfo":{"status":"ok","timestamp":1639519108733,"user_tz":300,"elapsed":546,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"946fc3a7-490a-42b8-c69a-175a87279773"},"id":"4Qsi4jKR7lMF","execution_count":263,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>with_drug</th>\n","      <th>time</th>\n","      <th>dosage</th>\n","      <th>drug</th>\n","      <th>g-0</th>\n","      <th>g-1</th>\n","      <th>g-2</th>\n","      <th>g-3</th>\n","      <th>g-4</th>\n","      <th>g-5</th>\n","      <th>g-6</th>\n","      <th>g-7</th>\n","      <th>g-8</th>\n","      <th>g-9</th>\n","      <th>g-10</th>\n","      <th>g-11</th>\n","      <th>g-12</th>\n","      <th>g-13</th>\n","      <th>g-14</th>\n","      <th>g-15</th>\n","      <th>g-16</th>\n","      <th>g-17</th>\n","      <th>g-18</th>\n","      <th>g-19</th>\n","      <th>g-20</th>\n","      <th>g-21</th>\n","      <th>g-22</th>\n","      <th>g-23</th>\n","      <th>g-24</th>\n","      <th>g-25</th>\n","      <th>g-26</th>\n","      <th>g-27</th>\n","      <th>g-28</th>\n","      <th>g-29</th>\n","      <th>g-30</th>\n","      <th>g-31</th>\n","      <th>g-32</th>\n","      <th>g-33</th>\n","      <th>g-34</th>\n","      <th>g-35</th>\n","      <th>...</th>\n","      <th>c-60</th>\n","      <th>c-61</th>\n","      <th>c-62</th>\n","      <th>c-63</th>\n","      <th>c-64</th>\n","      <th>c-65</th>\n","      <th>c-66</th>\n","      <th>c-67</th>\n","      <th>c-68</th>\n","      <th>c-69</th>\n","      <th>c-70</th>\n","      <th>c-71</th>\n","      <th>c-72</th>\n","      <th>c-73</th>\n","      <th>c-74</th>\n","      <th>c-75</th>\n","      <th>c-76</th>\n","      <th>c-77</th>\n","      <th>c-78</th>\n","      <th>c-79</th>\n","      <th>c-80</th>\n","      <th>c-81</th>\n","      <th>c-82</th>\n","      <th>c-83</th>\n","      <th>c-84</th>\n","      <th>c-85</th>\n","      <th>c-86</th>\n","      <th>c-87</th>\n","      <th>c-88</th>\n","      <th>c-89</th>\n","      <th>c-90</th>\n","      <th>c-91</th>\n","      <th>c-92</th>\n","      <th>c-93</th>\n","      <th>c-94</th>\n","      <th>c-95</th>\n","      <th>c-96</th>\n","      <th>c-97</th>\n","      <th>c-98</th>\n","      <th>c-99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>181.0</td>\n","      <td>0.4658</td>\n","      <td>1.4250</td>\n","      <td>-0.5632</td>\n","      <td>-0.0119</td>\n","      <td>0.6751</td>\n","      <td>-0.7467</td>\n","      <td>-0.1810</td>\n","      <td>0.6779</td>\n","      <td>0.5926</td>\n","      <td>1.3180</td>\n","      <td>0.0152</td>\n","      <td>-0.2709</td>\n","      <td>0.2239</td>\n","      <td>-0.0124</td>\n","      <td>0.3578</td>\n","      <td>0.0158</td>\n","      <td>-0.6066</td>\n","      <td>0.0202</td>\n","      <td>0.0000</td>\n","      <td>-0.2948</td>\n","      <td>-0.5171</td>\n","      <td>0.4444</td>\n","      <td>0.5350</td>\n","      <td>0.2812</td>\n","      <td>1.1870</td>\n","      <td>-0.2028</td>\n","      <td>0.2292</td>\n","      <td>-0.3417</td>\n","      <td>0.3714</td>\n","      <td>-0.9600</td>\n","      <td>-0.0175</td>\n","      <td>-0.8604</td>\n","      <td>0.4275</td>\n","      <td>-0.4485</td>\n","      <td>-1.6020</td>\n","      <td>0.5405</td>\n","      <td>...</td>\n","      <td>-0.1225</td>\n","      <td>-0.3381</td>\n","      <td>0.4055</td>\n","      <td>-0.3498</td>\n","      <td>0.1593</td>\n","      <td>0.2194</td>\n","      <td>-0.0765</td>\n","      <td>-1.6440</td>\n","      <td>-0.5519</td>\n","      <td>0.2824</td>\n","      <td>0.2647</td>\n","      <td>-0.0433</td>\n","      <td>0.5480</td>\n","      <td>0.4726</td>\n","      <td>-0.7551</td>\n","      <td>0.4549</td>\n","      <td>-0.6002</td>\n","      <td>-0.1714</td>\n","      <td>-0.0009</td>\n","      <td>-0.2587</td>\n","      <td>0.8485</td>\n","      <td>-0.1661</td>\n","      <td>-0.2362</td>\n","      <td>-0.0050</td>\n","      <td>-0.8434</td>\n","      <td>0.6395</td>\n","      <td>0.9370</td>\n","      <td>-0.9632</td>\n","      <td>0.2297</td>\n","      <td>-0.8573</td>\n","      <td>0.0575</td>\n","      <td>-0.5601</td>\n","      <td>-0.2339</td>\n","      <td>-0.2814</td>\n","      <td>0.2419</td>\n","      <td>0.7509</td>\n","      <td>0.5843</td>\n","      <td>-0.7467</td>\n","      <td>-0.1309</td>\n","      <td>-0.1908</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>274.0</td>\n","      <td>-0.5043</td>\n","      <td>0.1211</td>\n","      <td>-0.5380</td>\n","      <td>-0.3511</td>\n","      <td>-0.0050</td>\n","      <td>-0.0128</td>\n","      <td>-0.4338</td>\n","      <td>0.9652</td>\n","      <td>-0.3734</td>\n","      <td>0.6840</td>\n","      <td>-0.1578</td>\n","      <td>-0.6227</td>\n","      <td>-0.6514</td>\n","      <td>-1.4570</td>\n","      <td>0.2358</td>\n","      <td>0.3081</td>\n","      <td>-0.0632</td>\n","      <td>0.1040</td>\n","      <td>-0.1019</td>\n","      <td>0.5123</td>\n","      <td>0.5274</td>\n","      <td>-0.2736</td>\n","      <td>0.2426</td>\n","      <td>0.4924</td>\n","      <td>0.1726</td>\n","      <td>-0.6227</td>\n","      <td>-0.1724</td>\n","      <td>-0.0331</td>\n","      <td>0.8268</td>\n","      <td>-0.2341</td>\n","      <td>-0.4472</td>\n","      <td>-0.5801</td>\n","      <td>0.4156</td>\n","      <td>-0.6220</td>\n","      <td>0.9109</td>\n","      <td>0.1679</td>\n","      <td>...</td>\n","      <td>-0.0482</td>\n","      <td>0.6582</td>\n","      <td>-0.7727</td>\n","      <td>-0.1590</td>\n","      <td>1.6530</td>\n","      <td>0.0026</td>\n","      <td>-1.7780</td>\n","      <td>-0.4627</td>\n","      <td>-1.0200</td>\n","      <td>0.8589</td>\n","      <td>-0.2143</td>\n","      <td>0.7226</td>\n","      <td>0.5150</td>\n","      <td>1.0900</td>\n","      <td>-0.5075</td>\n","      <td>-0.1194</td>\n","      <td>-0.8222</td>\n","      <td>1.3570</td>\n","      <td>-1.4610</td>\n","      <td>0.6811</td>\n","      <td>0.0402</td>\n","      <td>-1.1650</td>\n","      <td>-0.4445</td>\n","      <td>1.5550</td>\n","      <td>-0.2412</td>\n","      <td>0.2904</td>\n","      <td>-0.7027</td>\n","      <td>-0.6599</td>\n","      <td>0.4470</td>\n","      <td>0.8200</td>\n","      <td>-0.1949</td>\n","      <td>0.0248</td>\n","      <td>0.7269</td>\n","      <td>-0.7356</td>\n","      <td>0.0433</td>\n","      <td>0.9164</td>\n","      <td>-0.8046</td>\n","      <td>-0.6839</td>\n","      <td>0.3994</td>\n","      <td>-1.4120</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>715.0</td>\n","      <td>1.1830</td>\n","      <td>-0.6798</td>\n","      <td>-0.2405</td>\n","      <td>-1.6620</td>\n","      <td>-0.1134</td>\n","      <td>0.4659</td>\n","      <td>0.0334</td>\n","      <td>0.0078</td>\n","      <td>0.3076</td>\n","      <td>1.1850</td>\n","      <td>-0.4538</td>\n","      <td>-0.0871</td>\n","      <td>-1.4850</td>\n","      <td>0.0621</td>\n","      <td>-0.5607</td>\n","      <td>0.6849</td>\n","      <td>0.4531</td>\n","      <td>0.3387</td>\n","      <td>-0.3851</td>\n","      <td>0.0585</td>\n","      <td>0.3828</td>\n","      <td>0.0106</td>\n","      <td>-0.5473</td>\n","      <td>0.4757</td>\n","      <td>0.2059</td>\n","      <td>-0.7943</td>\n","      <td>-1.6040</td>\n","      <td>0.6475</td>\n","      <td>0.8998</td>\n","      <td>1.0530</td>\n","      <td>-1.4710</td>\n","      <td>0.1649</td>\n","      <td>0.1244</td>\n","      <td>0.0705</td>\n","      <td>-1.5500</td>\n","      <td>-0.4618</td>\n","      <td>...</td>\n","      <td>-0.2990</td>\n","      <td>-1.4240</td>\n","      <td>-1.1740</td>\n","      <td>-0.7987</td>\n","      <td>-2.2690</td>\n","      <td>-2.0650</td>\n","      <td>-1.4460</td>\n","      <td>-0.8470</td>\n","      <td>-0.9399</td>\n","      <td>-0.9628</td>\n","      <td>0.4444</td>\n","      <td>-3.7130</td>\n","      <td>-0.3087</td>\n","      <td>0.3414</td>\n","      <td>-0.3110</td>\n","      <td>-2.9850</td>\n","      <td>-1.2670</td>\n","      <td>-0.9795</td>\n","      <td>-0.9623</td>\n","      <td>-1.0720</td>\n","      <td>-0.6720</td>\n","      <td>-1.6730</td>\n","      <td>-2.7360</td>\n","      <td>-1.0110</td>\n","      <td>-1.0510</td>\n","      <td>-2.9010</td>\n","      <td>0.0849</td>\n","      <td>-0.0971</td>\n","      <td>-0.9119</td>\n","      <td>-0.6381</td>\n","      <td>-0.3363</td>\n","      <td>-1.0470</td>\n","      <td>-1.3730</td>\n","      <td>-2.0460</td>\n","      <td>-1.5470</td>\n","      <td>0.5246</td>\n","      <td>-0.6099</td>\n","      <td>-1.0640</td>\n","      <td>-0.5936</td>\n","      <td>-1.2520</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>88.0</td>\n","      <td>1.2070</td>\n","      <td>1.4360</td>\n","      <td>3.1000</td>\n","      <td>-1.6010</td>\n","      <td>0.4305</td>\n","      <td>-0.5074</td>\n","      <td>-0.5459</td>\n","      <td>0.5481</td>\n","      <td>-0.6325</td>\n","      <td>0.8063</td>\n","      <td>0.0197</td>\n","      <td>-1.1110</td>\n","      <td>-0.3769</td>\n","      <td>-1.4050</td>\n","      <td>0.4654</td>\n","      <td>-0.2894</td>\n","      <td>-0.8753</td>\n","      <td>0.2664</td>\n","      <td>-0.1366</td>\n","      <td>0.0667</td>\n","      <td>-1.7760</td>\n","      <td>0.4284</td>\n","      <td>-0.6306</td>\n","      <td>1.0640</td>\n","      <td>1.5910</td>\n","      <td>-0.9320</td>\n","      <td>-0.8099</td>\n","      <td>-1.0860</td>\n","      <td>-1.2910</td>\n","      <td>-0.7128</td>\n","      <td>-1.1730</td>\n","      <td>-0.8182</td>\n","      <td>-0.0359</td>\n","      <td>-0.9337</td>\n","      <td>-0.7056</td>\n","      <td>-1.1850</td>\n","      <td>...</td>\n","      <td>-0.4556</td>\n","      <td>-1.2280</td>\n","      <td>-1.3430</td>\n","      <td>-0.6080</td>\n","      <td>-0.9565</td>\n","      <td>-1.4740</td>\n","      <td>-0.3885</td>\n","      <td>-0.3162</td>\n","      <td>-0.8547</td>\n","      <td>0.0757</td>\n","      <td>-0.7611</td>\n","      <td>-1.4490</td>\n","      <td>-1.2170</td>\n","      <td>-0.7900</td>\n","      <td>0.2431</td>\n","      <td>-0.6381</td>\n","      <td>-1.3550</td>\n","      <td>-0.6417</td>\n","      <td>-0.3015</td>\n","      <td>-0.6411</td>\n","      <td>-2.1010</td>\n","      <td>-1.3320</td>\n","      <td>-1.0300</td>\n","      <td>-0.8060</td>\n","      <td>-1.3420</td>\n","      <td>-1.0460</td>\n","      <td>0.0022</td>\n","      <td>-0.8869</td>\n","      <td>-1.2430</td>\n","      <td>-0.1014</td>\n","      <td>-0.7747</td>\n","      <td>-0.9214</td>\n","      <td>-0.3028</td>\n","      <td>0.1427</td>\n","      <td>-0.8732</td>\n","      <td>-0.1411</td>\n","      <td>-2.7130</td>\n","      <td>-1.3650</td>\n","      <td>-1.0090</td>\n","      <td>-1.2340</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>1568.0</td>\n","      <td>-0.0890</td>\n","      <td>2.1570</td>\n","      <td>-0.0651</td>\n","      <td>0.1690</td>\n","      <td>0.2054</td>\n","      <td>0.3834</td>\n","      <td>-0.5329</td>\n","      <td>-3.0980</td>\n","      <td>-0.8841</td>\n","      <td>1.0270</td>\n","      <td>0.2714</td>\n","      <td>1.1120</td>\n","      <td>0.1116</td>\n","      <td>0.0866</td>\n","      <td>-0.2262</td>\n","      <td>0.8512</td>\n","      <td>-0.1112</td>\n","      <td>-0.3537</td>\n","      <td>0.3570</td>\n","      <td>0.1949</td>\n","      <td>-0.0519</td>\n","      <td>-0.9191</td>\n","      <td>0.3706</td>\n","      <td>-0.3985</td>\n","      <td>0.6394</td>\n","      <td>-0.1821</td>\n","      <td>-0.1453</td>\n","      <td>0.3782</td>\n","      <td>-0.1988</td>\n","      <td>0.3422</td>\n","      <td>0.3115</td>\n","      <td>-0.7015</td>\n","      <td>0.0393</td>\n","      <td>0.9006</td>\n","      <td>0.5477</td>\n","      <td>-0.6315</td>\n","      <td>...</td>\n","      <td>-0.0680</td>\n","      <td>-0.3711</td>\n","      <td>0.5548</td>\n","      <td>0.8086</td>\n","      <td>0.6644</td>\n","      <td>0.1458</td>\n","      <td>0.9796</td>\n","      <td>0.3244</td>\n","      <td>1.0800</td>\n","      <td>0.3501</td>\n","      <td>0.5620</td>\n","      <td>1.5910</td>\n","      <td>0.6267</td>\n","      <td>0.6385</td>\n","      <td>0.9774</td>\n","      <td>-0.5422</td>\n","      <td>0.4364</td>\n","      <td>0.4865</td>\n","      <td>0.3531</td>\n","      <td>0.6106</td>\n","      <td>0.6259</td>\n","      <td>0.2252</td>\n","      <td>0.9836</td>\n","      <td>0.3798</td>\n","      <td>-0.9024</td>\n","      <td>0.4252</td>\n","      <td>0.5749</td>\n","      <td>0.8091</td>\n","      <td>0.2209</td>\n","      <td>0.8947</td>\n","      <td>0.5315</td>\n","      <td>-0.0385</td>\n","      <td>0.6147</td>\n","      <td>0.3578</td>\n","      <td>0.0392</td>\n","      <td>1.1650</td>\n","      <td>0.2582</td>\n","      <td>1.1030</td>\n","      <td>0.6253</td>\n","      <td>0.9172</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 876 columns</p>\n","</div>"],"text/plain":["   with_drug  time dosage    drug  ...    c-96    c-97    c-98    c-99\n","0       True    24     D2   181.0  ...  0.5843 -0.7467 -0.1309 -0.1908\n","1       True    24     D1   274.0  ... -0.8046 -0.6839  0.3994 -1.4120\n","2       True    72     D2   715.0  ... -0.6099 -1.0640 -0.5936 -1.2520\n","3       True    48     D2    88.0  ... -2.7130 -1.3650 -1.0090 -1.2340\n","4       True    72     D2  1568.0  ...  0.2582  1.1030  0.6253  0.9172\n","\n","[5 rows x 876 columns]"]},"metadata":{},"execution_count":263}]},{"cell_type":"code","source":["# temp = pd.get_dummies(one_moa_feature[one_moa_feature.iloc[:, -1] == 'train'].drop(columns=['id', 'dtype']))\n","# drug_cols = [col for col in temp.columns if col.startswith('drug_')]\n","# drug_col = (temp[drug_cols].idxmax(axis=0))-min(temp[drug_cols].idxmax(axis=0))\n","# train_features['drug'] = drug_col.reset_index(drop=True).astype(int)\n","# train_features.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"id":"wR36Vbep5TYp","executionInfo":{"status":"ok","timestamp":1639518921958,"user_tz":300,"elapsed":474,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"aa5f5c89-dd5c-4258-d44c-9c54c28718dd"},"id":"wR36Vbep5TYp","execution_count":259,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>with_drug</th>\n","      <th>time</th>\n","      <th>dosage</th>\n","      <th>drug</th>\n","      <th>g-0</th>\n","      <th>g-1</th>\n","      <th>g-2</th>\n","      <th>g-3</th>\n","      <th>g-4</th>\n","      <th>g-5</th>\n","      <th>g-6</th>\n","      <th>g-7</th>\n","      <th>g-8</th>\n","      <th>g-9</th>\n","      <th>g-10</th>\n","      <th>g-11</th>\n","      <th>g-12</th>\n","      <th>g-13</th>\n","      <th>g-14</th>\n","      <th>g-15</th>\n","      <th>g-16</th>\n","      <th>g-17</th>\n","      <th>g-18</th>\n","      <th>g-19</th>\n","      <th>g-20</th>\n","      <th>g-21</th>\n","      <th>g-22</th>\n","      <th>g-23</th>\n","      <th>g-24</th>\n","      <th>g-25</th>\n","      <th>g-26</th>\n","      <th>g-27</th>\n","      <th>g-28</th>\n","      <th>g-29</th>\n","      <th>g-30</th>\n","      <th>g-31</th>\n","      <th>g-32</th>\n","      <th>g-33</th>\n","      <th>g-34</th>\n","      <th>g-35</th>\n","      <th>...</th>\n","      <th>c-60</th>\n","      <th>c-61</th>\n","      <th>c-62</th>\n","      <th>c-63</th>\n","      <th>c-64</th>\n","      <th>c-65</th>\n","      <th>c-66</th>\n","      <th>c-67</th>\n","      <th>c-68</th>\n","      <th>c-69</th>\n","      <th>c-70</th>\n","      <th>c-71</th>\n","      <th>c-72</th>\n","      <th>c-73</th>\n","      <th>c-74</th>\n","      <th>c-75</th>\n","      <th>c-76</th>\n","      <th>c-77</th>\n","      <th>c-78</th>\n","      <th>c-79</th>\n","      <th>c-80</th>\n","      <th>c-81</th>\n","      <th>c-82</th>\n","      <th>c-83</th>\n","      <th>c-84</th>\n","      <th>c-85</th>\n","      <th>c-86</th>\n","      <th>c-87</th>\n","      <th>c-88</th>\n","      <th>c-89</th>\n","      <th>c-90</th>\n","      <th>c-91</th>\n","      <th>c-92</th>\n","      <th>c-93</th>\n","      <th>c-94</th>\n","      <th>c-95</th>\n","      <th>c-96</th>\n","      <th>c-97</th>\n","      <th>c-98</th>\n","      <th>c-99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>243.0</td>\n","      <td>0.4658</td>\n","      <td>1.4250</td>\n","      <td>-0.5632</td>\n","      <td>-0.0119</td>\n","      <td>0.6751</td>\n","      <td>-0.7467</td>\n","      <td>-0.1810</td>\n","      <td>0.6779</td>\n","      <td>0.5926</td>\n","      <td>1.3180</td>\n","      <td>0.0152</td>\n","      <td>-0.2709</td>\n","      <td>0.2239</td>\n","      <td>-0.0124</td>\n","      <td>0.3578</td>\n","      <td>0.0158</td>\n","      <td>-0.6066</td>\n","      <td>0.0202</td>\n","      <td>0.0000</td>\n","      <td>-0.2948</td>\n","      <td>-0.5171</td>\n","      <td>0.4444</td>\n","      <td>0.5350</td>\n","      <td>0.2812</td>\n","      <td>1.1870</td>\n","      <td>-0.2028</td>\n","      <td>0.2292</td>\n","      <td>-0.3417</td>\n","      <td>0.3714</td>\n","      <td>-0.9600</td>\n","      <td>-0.0175</td>\n","      <td>-0.8604</td>\n","      <td>0.4275</td>\n","      <td>-0.4485</td>\n","      <td>-1.6020</td>\n","      <td>0.5405</td>\n","      <td>...</td>\n","      <td>-0.1225</td>\n","      <td>-0.3381</td>\n","      <td>0.4055</td>\n","      <td>-0.3498</td>\n","      <td>0.1593</td>\n","      <td>0.2194</td>\n","      <td>-0.0765</td>\n","      <td>-1.6440</td>\n","      <td>-0.5519</td>\n","      <td>0.2824</td>\n","      <td>0.2647</td>\n","      <td>-0.0433</td>\n","      <td>0.5480</td>\n","      <td>0.4726</td>\n","      <td>-0.7551</td>\n","      <td>0.4549</td>\n","      <td>-0.6002</td>\n","      <td>-0.1714</td>\n","      <td>-0.0009</td>\n","      <td>-0.2587</td>\n","      <td>0.8485</td>\n","      <td>-0.1661</td>\n","      <td>-0.2362</td>\n","      <td>-0.0050</td>\n","      <td>-0.8434</td>\n","      <td>0.6395</td>\n","      <td>0.9370</td>\n","      <td>-0.9632</td>\n","      <td>0.2297</td>\n","      <td>-0.8573</td>\n","      <td>0.0575</td>\n","      <td>-0.5601</td>\n","      <td>-0.2339</td>\n","      <td>-0.2814</td>\n","      <td>0.2419</td>\n","      <td>0.7509</td>\n","      <td>0.5843</td>\n","      <td>-0.7467</td>\n","      <td>-0.1309</td>\n","      <td>-0.1908</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>382.0</td>\n","      <td>-0.5043</td>\n","      <td>0.1211</td>\n","      <td>-0.5380</td>\n","      <td>-0.3511</td>\n","      <td>-0.0050</td>\n","      <td>-0.0128</td>\n","      <td>-0.4338</td>\n","      <td>0.9652</td>\n","      <td>-0.3734</td>\n","      <td>0.6840</td>\n","      <td>-0.1578</td>\n","      <td>-0.6227</td>\n","      <td>-0.6514</td>\n","      <td>-1.4570</td>\n","      <td>0.2358</td>\n","      <td>0.3081</td>\n","      <td>-0.0632</td>\n","      <td>0.1040</td>\n","      <td>-0.1019</td>\n","      <td>0.5123</td>\n","      <td>0.5274</td>\n","      <td>-0.2736</td>\n","      <td>0.2426</td>\n","      <td>0.4924</td>\n","      <td>0.1726</td>\n","      <td>-0.6227</td>\n","      <td>-0.1724</td>\n","      <td>-0.0331</td>\n","      <td>0.8268</td>\n","      <td>-0.2341</td>\n","      <td>-0.4472</td>\n","      <td>-0.5801</td>\n","      <td>0.4156</td>\n","      <td>-0.6220</td>\n","      <td>0.9109</td>\n","      <td>0.1679</td>\n","      <td>...</td>\n","      <td>-0.0482</td>\n","      <td>0.6582</td>\n","      <td>-0.7727</td>\n","      <td>-0.1590</td>\n","      <td>1.6530</td>\n","      <td>0.0026</td>\n","      <td>-1.7780</td>\n","      <td>-0.4627</td>\n","      <td>-1.0200</td>\n","      <td>0.8589</td>\n","      <td>-0.2143</td>\n","      <td>0.7226</td>\n","      <td>0.5150</td>\n","      <td>1.0900</td>\n","      <td>-0.5075</td>\n","      <td>-0.1194</td>\n","      <td>-0.8222</td>\n","      <td>1.3570</td>\n","      <td>-1.4610</td>\n","      <td>0.6811</td>\n","      <td>0.0402</td>\n","      <td>-1.1650</td>\n","      <td>-0.4445</td>\n","      <td>1.5550</td>\n","      <td>-0.2412</td>\n","      <td>0.2904</td>\n","      <td>-0.7027</td>\n","      <td>-0.6599</td>\n","      <td>0.4470</td>\n","      <td>0.8200</td>\n","      <td>-0.1949</td>\n","      <td>0.0248</td>\n","      <td>0.7269</td>\n","      <td>-0.7356</td>\n","      <td>0.0433</td>\n","      <td>0.9164</td>\n","      <td>-0.8046</td>\n","      <td>-0.6839</td>\n","      <td>0.3994</td>\n","      <td>-1.4120</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>1003.0</td>\n","      <td>1.1830</td>\n","      <td>-0.6798</td>\n","      <td>-0.2405</td>\n","      <td>-1.6620</td>\n","      <td>-0.1134</td>\n","      <td>0.4659</td>\n","      <td>0.0334</td>\n","      <td>0.0078</td>\n","      <td>0.3076</td>\n","      <td>1.1850</td>\n","      <td>-0.4538</td>\n","      <td>-0.0871</td>\n","      <td>-1.4850</td>\n","      <td>0.0621</td>\n","      <td>-0.5607</td>\n","      <td>0.6849</td>\n","      <td>0.4531</td>\n","      <td>0.3387</td>\n","      <td>-0.3851</td>\n","      <td>0.0585</td>\n","      <td>0.3828</td>\n","      <td>0.0106</td>\n","      <td>-0.5473</td>\n","      <td>0.4757</td>\n","      <td>0.2059</td>\n","      <td>-0.7943</td>\n","      <td>-1.6040</td>\n","      <td>0.6475</td>\n","      <td>0.8998</td>\n","      <td>1.0530</td>\n","      <td>-1.4710</td>\n","      <td>0.1649</td>\n","      <td>0.1244</td>\n","      <td>0.0705</td>\n","      <td>-1.5500</td>\n","      <td>-0.4618</td>\n","      <td>...</td>\n","      <td>-0.2990</td>\n","      <td>-1.4240</td>\n","      <td>-1.1740</td>\n","      <td>-0.7987</td>\n","      <td>-2.2690</td>\n","      <td>-2.0650</td>\n","      <td>-1.4460</td>\n","      <td>-0.8470</td>\n","      <td>-0.9399</td>\n","      <td>-0.9628</td>\n","      <td>0.4444</td>\n","      <td>-3.7130</td>\n","      <td>-0.3087</td>\n","      <td>0.3414</td>\n","      <td>-0.3110</td>\n","      <td>-2.9850</td>\n","      <td>-1.2670</td>\n","      <td>-0.9795</td>\n","      <td>-0.9623</td>\n","      <td>-1.0720</td>\n","      <td>-0.6720</td>\n","      <td>-1.6730</td>\n","      <td>-2.7360</td>\n","      <td>-1.0110</td>\n","      <td>-1.0510</td>\n","      <td>-2.9010</td>\n","      <td>0.0849</td>\n","      <td>-0.0971</td>\n","      <td>-0.9119</td>\n","      <td>-0.6381</td>\n","      <td>-0.3363</td>\n","      <td>-1.0470</td>\n","      <td>-1.3730</td>\n","      <td>-2.0460</td>\n","      <td>-1.5470</td>\n","      <td>0.5246</td>\n","      <td>-0.6099</td>\n","      <td>-1.0640</td>\n","      <td>-0.5936</td>\n","      <td>-1.2520</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>125.0</td>\n","      <td>1.2070</td>\n","      <td>1.4360</td>\n","      <td>3.1000</td>\n","      <td>-1.6010</td>\n","      <td>0.4305</td>\n","      <td>-0.5074</td>\n","      <td>-0.5459</td>\n","      <td>0.5481</td>\n","      <td>-0.6325</td>\n","      <td>0.8063</td>\n","      <td>0.0197</td>\n","      <td>-1.1110</td>\n","      <td>-0.3769</td>\n","      <td>-1.4050</td>\n","      <td>0.4654</td>\n","      <td>-0.2894</td>\n","      <td>-0.8753</td>\n","      <td>0.2664</td>\n","      <td>-0.1366</td>\n","      <td>0.0667</td>\n","      <td>-1.7760</td>\n","      <td>0.4284</td>\n","      <td>-0.6306</td>\n","      <td>1.0640</td>\n","      <td>1.5910</td>\n","      <td>-0.9320</td>\n","      <td>-0.8099</td>\n","      <td>-1.0860</td>\n","      <td>-1.2910</td>\n","      <td>-0.7128</td>\n","      <td>-1.1730</td>\n","      <td>-0.8182</td>\n","      <td>-0.0359</td>\n","      <td>-0.9337</td>\n","      <td>-0.7056</td>\n","      <td>-1.1850</td>\n","      <td>...</td>\n","      <td>-0.4556</td>\n","      <td>-1.2280</td>\n","      <td>-1.3430</td>\n","      <td>-0.6080</td>\n","      <td>-0.9565</td>\n","      <td>-1.4740</td>\n","      <td>-0.3885</td>\n","      <td>-0.3162</td>\n","      <td>-0.8547</td>\n","      <td>0.0757</td>\n","      <td>-0.7611</td>\n","      <td>-1.4490</td>\n","      <td>-1.2170</td>\n","      <td>-0.7900</td>\n","      <td>0.2431</td>\n","      <td>-0.6381</td>\n","      <td>-1.3550</td>\n","      <td>-0.6417</td>\n","      <td>-0.3015</td>\n","      <td>-0.6411</td>\n","      <td>-2.1010</td>\n","      <td>-1.3320</td>\n","      <td>-1.0300</td>\n","      <td>-0.8060</td>\n","      <td>-1.3420</td>\n","      <td>-1.0460</td>\n","      <td>0.0022</td>\n","      <td>-0.8869</td>\n","      <td>-1.2430</td>\n","      <td>-0.1014</td>\n","      <td>-0.7747</td>\n","      <td>-0.9214</td>\n","      <td>-0.3028</td>\n","      <td>0.1427</td>\n","      <td>-0.8732</td>\n","      <td>-0.1411</td>\n","      <td>-2.7130</td>\n","      <td>-1.3650</td>\n","      <td>-1.0090</td>\n","      <td>-1.2340</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>2216.0</td>\n","      <td>-0.0890</td>\n","      <td>2.1570</td>\n","      <td>-0.0651</td>\n","      <td>0.1690</td>\n","      <td>0.2054</td>\n","      <td>0.3834</td>\n","      <td>-0.5329</td>\n","      <td>-3.0980</td>\n","      <td>-0.8841</td>\n","      <td>1.0270</td>\n","      <td>0.2714</td>\n","      <td>1.1120</td>\n","      <td>0.1116</td>\n","      <td>0.0866</td>\n","      <td>-0.2262</td>\n","      <td>0.8512</td>\n","      <td>-0.1112</td>\n","      <td>-0.3537</td>\n","      <td>0.3570</td>\n","      <td>0.1949</td>\n","      <td>-0.0519</td>\n","      <td>-0.9191</td>\n","      <td>0.3706</td>\n","      <td>-0.3985</td>\n","      <td>0.6394</td>\n","      <td>-0.1821</td>\n","      <td>-0.1453</td>\n","      <td>0.3782</td>\n","      <td>-0.1988</td>\n","      <td>0.3422</td>\n","      <td>0.3115</td>\n","      <td>-0.7015</td>\n","      <td>0.0393</td>\n","      <td>0.9006</td>\n","      <td>0.5477</td>\n","      <td>-0.6315</td>\n","      <td>...</td>\n","      <td>-0.0680</td>\n","      <td>-0.3711</td>\n","      <td>0.5548</td>\n","      <td>0.8086</td>\n","      <td>0.6644</td>\n","      <td>0.1458</td>\n","      <td>0.9796</td>\n","      <td>0.3244</td>\n","      <td>1.0800</td>\n","      <td>0.3501</td>\n","      <td>0.5620</td>\n","      <td>1.5910</td>\n","      <td>0.6267</td>\n","      <td>0.6385</td>\n","      <td>0.9774</td>\n","      <td>-0.5422</td>\n","      <td>0.4364</td>\n","      <td>0.4865</td>\n","      <td>0.3531</td>\n","      <td>0.6106</td>\n","      <td>0.6259</td>\n","      <td>0.2252</td>\n","      <td>0.9836</td>\n","      <td>0.3798</td>\n","      <td>-0.9024</td>\n","      <td>0.4252</td>\n","      <td>0.5749</td>\n","      <td>0.8091</td>\n","      <td>0.2209</td>\n","      <td>0.8947</td>\n","      <td>0.5315</td>\n","      <td>-0.0385</td>\n","      <td>0.6147</td>\n","      <td>0.3578</td>\n","      <td>0.0392</td>\n","      <td>1.1650</td>\n","      <td>0.2582</td>\n","      <td>1.1030</td>\n","      <td>0.6253</td>\n","      <td>0.9172</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 876 columns</p>\n","</div>"],"text/plain":["   with_drug  time dosage    drug  ...    c-96    c-97    c-98    c-99\n","0       True    24     D2   243.0  ...  0.5843 -0.7467 -0.1309 -0.1908\n","1       True    24     D1   382.0  ... -0.8046 -0.6839  0.3994 -1.4120\n","2       True    72     D2  1003.0  ... -0.6099 -1.0640 -0.5936 -1.2520\n","3       True    48     D2   125.0  ... -2.7130 -1.3650 -1.0090 -1.2340\n","4       True    72     D2  2216.0  ...  0.2582  1.1030  0.6253  0.9172\n","\n","[5 rows x 876 columns]"]},"metadata":{},"execution_count":259}]},{"cell_type":"code","source":["# train_features.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPX6HPxs6WJP","executionInfo":{"status":"ok","timestamp":1639518498832,"user_tz":300,"elapsed":151,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"1c770dba-e73c-41f3-b7b2-96a8741804a7"},"id":"TPX6HPxs6WJP","execution_count":234,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6009, 2674)"]},"metadata":{},"execution_count":234}]},{"cell_type":"code","source":["# (train_features[drug_cols].idxmax(axis=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFWpiw8R7cTL","executionInfo":{"status":"ok","timestamp":1639518686520,"user_tz":300,"elapsed":116,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"37b3ff00-ae96-4292-d178-a029f5d90cef"},"id":"wFWpiw8R7cTL","execution_count":245,"outputs":[{"output_type":"execute_result","data":{"text/plain":["drug_00321ea80    3934\n","drug_0060e686f    4073\n","drug_00898e82c    4694\n","drug_009a5da05    3816\n","drug_00d2de1d8    5907\n","                  ... \n","drug_ff551f3a3    4738\n","drug_ff9565933    9538\n","drug_ffd66e220    3822\n","drug_ffe357f8f    8653\n","drug_ffed8e1c9    6232\n","Length: 1798, dtype: int64"]},"metadata":{},"execution_count":245}]},{"cell_type":"code","source":["# drug_col = (temp[drug_cols].idxmax(axis=0))-min(temp[drug_cols].idxmax(axis=0))\n","# drug_col.reset_index(drop=True).astype(int)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccb8R95Y5dXS","executionInfo":{"status":"ok","timestamp":1639518881703,"user_tz":300,"elapsed":147,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"4c527078-f36c-4e98-f875-abaabd0ebefe"},"id":"ccb8R95Y5dXS","execution_count":256,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        243\n","1        382\n","2       1003\n","3        125\n","4       2216\n","        ... \n","1793    1047\n","1794    5847\n","1795     131\n","1796    4962\n","1797    2541\n","Length: 1798, dtype: int64"]},"metadata":{},"execution_count":256}]},{"cell_type":"code","source":["# pd.get_dummies(one_moa_feature[one_moa_feature.iloc[:, -1] == 'train'].drop(columns=['id', 'dtype'])).columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"722a35lP4iit","executionInfo":{"status":"ok","timestamp":1639518072577,"user_tz":300,"elapsed":270,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"17748afd-d2de-49f7-9079-81de11bf405f"},"id":"722a35lP4iit","execution_count":214,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>with_drug</th>\n","      <th>time</th>\n","      <th>g-0</th>\n","      <th>g-1</th>\n","      <th>g-2</th>\n","      <th>g-3</th>\n","      <th>g-4</th>\n","      <th>g-5</th>\n","      <th>g-6</th>\n","      <th>g-7</th>\n","      <th>g-8</th>\n","      <th>g-9</th>\n","      <th>g-10</th>\n","      <th>g-11</th>\n","      <th>g-12</th>\n","      <th>g-13</th>\n","      <th>g-14</th>\n","      <th>g-15</th>\n","      <th>g-16</th>\n","      <th>g-17</th>\n","      <th>g-18</th>\n","      <th>g-19</th>\n","      <th>g-20</th>\n","      <th>g-21</th>\n","      <th>g-22</th>\n","      <th>g-23</th>\n","      <th>g-24</th>\n","      <th>g-25</th>\n","      <th>g-26</th>\n","      <th>g-27</th>\n","      <th>g-28</th>\n","      <th>g-29</th>\n","      <th>g-30</th>\n","      <th>g-31</th>\n","      <th>g-32</th>\n","      <th>g-33</th>\n","      <th>g-34</th>\n","      <th>g-35</th>\n","      <th>g-36</th>\n","      <th>g-37</th>\n","      <th>...</th>\n","      <th>drug_fb25cbce2</th>\n","      <th>drug_fb5164119</th>\n","      <th>drug_fb67ca7d9</th>\n","      <th>drug_fb69fd749</th>\n","      <th>drug_fb6c2c373</th>\n","      <th>drug_fb85944a6</th>\n","      <th>drug_fbd797b85</th>\n","      <th>drug_fc61cc291</th>\n","      <th>drug_fc89b3c68</th>\n","      <th>drug_fc9706723</th>\n","      <th>drug_fc9c586b9</th>\n","      <th>drug_fc9cc6ec4</th>\n","      <th>drug_fcafcf5a9</th>\n","      <th>drug_fcb7bf70f</th>\n","      <th>drug_fcc0d5d89</th>\n","      <th>drug_fcfed83c3</th>\n","      <th>drug_fd0ae9d6b</th>\n","      <th>drug_fd0e986aa</th>\n","      <th>drug_fd3b67efb</th>\n","      <th>drug_fd4387eac</th>\n","      <th>drug_fd68e0363</th>\n","      <th>drug_fdbbb98fa</th>\n","      <th>drug_fdda3eb67</th>\n","      <th>drug_fdf3069d4</th>\n","      <th>drug_fdf9c5a5d</th>\n","      <th>drug_fe05943c9</th>\n","      <th>drug_fe0f55365</th>\n","      <th>drug_fe1c34dbe</th>\n","      <th>drug_fe213e3a3</th>\n","      <th>drug_fe37066fc</th>\n","      <th>drug_fea7e5d15</th>\n","      <th>drug_feb9315c0</th>\n","      <th>drug_fefd9f534</th>\n","      <th>drug_ff270e1e7</th>\n","      <th>drug_ff32409d8</th>\n","      <th>drug_ff551f3a3</th>\n","      <th>drug_ff9565933</th>\n","      <th>drug_ffd66e220</th>\n","      <th>drug_ffe357f8f</th>\n","      <th>drug_ffed8e1c9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3691</th>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>0.4658</td>\n","      <td>1.4250</td>\n","      <td>-0.5632</td>\n","      <td>-0.0119</td>\n","      <td>0.6751</td>\n","      <td>-0.7467</td>\n","      <td>-0.1810</td>\n","      <td>0.6779</td>\n","      <td>0.5926</td>\n","      <td>1.3180</td>\n","      <td>0.0152</td>\n","      <td>-0.2709</td>\n","      <td>0.2239</td>\n","      <td>-0.0124</td>\n","      <td>0.3578</td>\n","      <td>0.0158</td>\n","      <td>-0.6066</td>\n","      <td>0.0202</td>\n","      <td>0.0000</td>\n","      <td>-0.2948</td>\n","      <td>-0.5171</td>\n","      <td>0.4444</td>\n","      <td>0.5350</td>\n","      <td>0.2812</td>\n","      <td>1.1870</td>\n","      <td>-0.2028</td>\n","      <td>0.2292</td>\n","      <td>-0.3417</td>\n","      <td>0.3714</td>\n","      <td>-0.9600</td>\n","      <td>-0.0175</td>\n","      <td>-0.8604</td>\n","      <td>0.4275</td>\n","      <td>-0.4485</td>\n","      <td>-1.6020</td>\n","      <td>0.5405</td>\n","      <td>-0.1677</td>\n","      <td>-1.1300</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3692</th>\n","      <td>True</td>\n","      <td>24</td>\n","      <td>-0.5043</td>\n","      <td>0.1211</td>\n","      <td>-0.5380</td>\n","      <td>-0.3511</td>\n","      <td>-0.0050</td>\n","      <td>-0.0128</td>\n","      <td>-0.4338</td>\n","      <td>0.9652</td>\n","      <td>-0.3734</td>\n","      <td>0.6840</td>\n","      <td>-0.1578</td>\n","      <td>-0.6227</td>\n","      <td>-0.6514</td>\n","      <td>-1.4570</td>\n","      <td>0.2358</td>\n","      <td>0.3081</td>\n","      <td>-0.0632</td>\n","      <td>0.1040</td>\n","      <td>-0.1019</td>\n","      <td>0.5123</td>\n","      <td>0.5274</td>\n","      <td>-0.2736</td>\n","      <td>0.2426</td>\n","      <td>0.4924</td>\n","      <td>0.1726</td>\n","      <td>-0.6227</td>\n","      <td>-0.1724</td>\n","      <td>-0.0331</td>\n","      <td>0.8268</td>\n","      <td>-0.2341</td>\n","      <td>-0.4472</td>\n","      <td>-0.5801</td>\n","      <td>0.4156</td>\n","      <td>-0.6220</td>\n","      <td>0.9109</td>\n","      <td>0.1679</td>\n","      <td>-0.1161</td>\n","      <td>0.8091</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3693</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>1.1830</td>\n","      <td>-0.6798</td>\n","      <td>-0.2405</td>\n","      <td>-1.6620</td>\n","      <td>-0.1134</td>\n","      <td>0.4659</td>\n","      <td>0.0334</td>\n","      <td>0.0078</td>\n","      <td>0.3076</td>\n","      <td>1.1850</td>\n","      <td>-0.4538</td>\n","      <td>-0.0871</td>\n","      <td>-1.4850</td>\n","      <td>0.0621</td>\n","      <td>-0.5607</td>\n","      <td>0.6849</td>\n","      <td>0.4531</td>\n","      <td>0.3387</td>\n","      <td>-0.3851</td>\n","      <td>0.0585</td>\n","      <td>0.3828</td>\n","      <td>0.0106</td>\n","      <td>-0.5473</td>\n","      <td>0.4757</td>\n","      <td>0.2059</td>\n","      <td>-0.7943</td>\n","      <td>-1.6040</td>\n","      <td>0.6475</td>\n","      <td>0.8998</td>\n","      <td>1.0530</td>\n","      <td>-1.4710</td>\n","      <td>0.1649</td>\n","      <td>0.1244</td>\n","      <td>0.0705</td>\n","      <td>-1.5500</td>\n","      <td>-0.4618</td>\n","      <td>-0.2600</td>\n","      <td>-0.7565</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3694</th>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>1.2070</td>\n","      <td>1.4360</td>\n","      <td>3.1000</td>\n","      <td>-1.6010</td>\n","      <td>0.4305</td>\n","      <td>-0.5074</td>\n","      <td>-0.5459</td>\n","      <td>0.5481</td>\n","      <td>-0.6325</td>\n","      <td>0.8063</td>\n","      <td>0.0197</td>\n","      <td>-1.1110</td>\n","      <td>-0.3769</td>\n","      <td>-1.4050</td>\n","      <td>0.4654</td>\n","      <td>-0.2894</td>\n","      <td>-0.8753</td>\n","      <td>0.2664</td>\n","      <td>-0.1366</td>\n","      <td>0.0667</td>\n","      <td>-1.7760</td>\n","      <td>0.4284</td>\n","      <td>-0.6306</td>\n","      <td>1.0640</td>\n","      <td>1.5910</td>\n","      <td>-0.9320</td>\n","      <td>-0.8099</td>\n","      <td>-1.0860</td>\n","      <td>-1.2910</td>\n","      <td>-0.7128</td>\n","      <td>-1.1730</td>\n","      <td>-0.8182</td>\n","      <td>-0.0359</td>\n","      <td>-0.9337</td>\n","      <td>-0.7056</td>\n","      <td>-1.1850</td>\n","      <td>-2.1730</td>\n","      <td>-0.0758</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3696</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>-0.0890</td>\n","      <td>2.1570</td>\n","      <td>-0.0651</td>\n","      <td>0.1690</td>\n","      <td>0.2054</td>\n","      <td>0.3834</td>\n","      <td>-0.5329</td>\n","      <td>-3.0980</td>\n","      <td>-0.8841</td>\n","      <td>1.0270</td>\n","      <td>0.2714</td>\n","      <td>1.1120</td>\n","      <td>0.1116</td>\n","      <td>0.0866</td>\n","      <td>-0.2262</td>\n","      <td>0.8512</td>\n","      <td>-0.1112</td>\n","      <td>-0.3537</td>\n","      <td>0.3570</td>\n","      <td>0.1949</td>\n","      <td>-0.0519</td>\n","      <td>-0.9191</td>\n","      <td>0.3706</td>\n","      <td>-0.3985</td>\n","      <td>0.6394</td>\n","      <td>-0.1821</td>\n","      <td>-0.1453</td>\n","      <td>0.3782</td>\n","      <td>-0.1988</td>\n","      <td>0.3422</td>\n","      <td>0.3115</td>\n","      <td>-0.7015</td>\n","      <td>0.0393</td>\n","      <td>0.9006</td>\n","      <td>0.5477</td>\n","      <td>-0.6315</td>\n","      <td>-0.0088</td>\n","      <td>-0.3395</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12291</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>-0.5946</td>\n","      <td>0.1265</td>\n","      <td>-2.1300</td>\n","      <td>0.5877</td>\n","      <td>-0.0638</td>\n","      <td>1.2800</td>\n","      <td>0.0022</td>\n","      <td>0.3328</td>\n","      <td>-0.2755</td>\n","      <td>0.4422</td>\n","      <td>-0.4262</td>\n","      <td>1.0450</td>\n","      <td>-1.7510</td>\n","      <td>0.2034</td>\n","      <td>-1.8510</td>\n","      <td>-0.1541</td>\n","      <td>0.1231</td>\n","      <td>-0.3735</td>\n","      <td>-0.3372</td>\n","      <td>0.4182</td>\n","      <td>-0.2800</td>\n","      <td>0.0267</td>\n","      <td>-0.1248</td>\n","      <td>-0.7541</td>\n","      <td>0.9430</td>\n","      <td>-0.4291</td>\n","      <td>0.2108</td>\n","      <td>0.4811</td>\n","      <td>-1.3890</td>\n","      <td>-0.0856</td>\n","      <td>0.2081</td>\n","      <td>-0.7334</td>\n","      <td>0.0875</td>\n","      <td>-0.0537</td>\n","      <td>0.6486</td>\n","      <td>0.9708</td>\n","      <td>-0.8790</td>\n","      <td>-0.2281</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12293</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>-0.4330</td>\n","      <td>-1.3590</td>\n","      <td>-0.3701</td>\n","      <td>0.7571</td>\n","      <td>0.6822</td>\n","      <td>-0.1997</td>\n","      <td>0.1881</td>\n","      <td>-0.7703</td>\n","      <td>-0.0948</td>\n","      <td>0.6848</td>\n","      <td>0.0615</td>\n","      <td>0.1454</td>\n","      <td>0.5249</td>\n","      <td>0.6209</td>\n","      <td>-0.5181</td>\n","      <td>-0.0865</td>\n","      <td>1.3890</td>\n","      <td>0.3893</td>\n","      <td>-0.0307</td>\n","      <td>0.5513</td>\n","      <td>-0.2427</td>\n","      <td>0.5250</td>\n","      <td>-0.7332</td>\n","      <td>-0.1490</td>\n","      <td>0.6810</td>\n","      <td>-0.8341</td>\n","      <td>0.0717</td>\n","      <td>-1.3100</td>\n","      <td>0.5138</td>\n","      <td>0.0087</td>\n","      <td>-0.7729</td>\n","      <td>-0.3164</td>\n","      <td>-0.1451</td>\n","      <td>-0.7249</td>\n","      <td>0.5393</td>\n","      <td>0.2467</td>\n","      <td>0.1723</td>\n","      <td>0.1302</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12294</th>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>0.4123</td>\n","      <td>-0.1551</td>\n","      <td>1.8100</td>\n","      <td>0.5042</td>\n","      <td>-1.2380</td>\n","      <td>-0.4582</td>\n","      <td>0.6316</td>\n","      <td>0.3722</td>\n","      <td>0.5405</td>\n","      <td>0.6720</td>\n","      <td>0.3912</td>\n","      <td>-0.9087</td>\n","      <td>0.5464</td>\n","      <td>-0.4654</td>\n","      <td>1.2900</td>\n","      <td>-0.4442</td>\n","      <td>0.6625</td>\n","      <td>1.1690</td>\n","      <td>0.1069</td>\n","      <td>-0.0654</td>\n","      <td>1.3430</td>\n","      <td>-0.3094</td>\n","      <td>1.4910</td>\n","      <td>0.3076</td>\n","      <td>0.0052</td>\n","      <td>-0.6171</td>\n","      <td>0.1582</td>\n","      <td>0.5656</td>\n","      <td>0.1409</td>\n","      <td>-0.4165</td>\n","      <td>0.5082</td>\n","      <td>-0.1683</td>\n","      <td>-0.3145</td>\n","      <td>-1.6070</td>\n","      <td>0.7890</td>\n","      <td>1.4430</td>\n","      <td>0.5275</td>\n","      <td>-0.2605</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12296</th>\n","      <td>True</td>\n","      <td>48</td>\n","      <td>0.1420</td>\n","      <td>-0.3696</td>\n","      <td>-0.0093</td>\n","      <td>-0.2495</td>\n","      <td>-0.0175</td>\n","      <td>0.0959</td>\n","      <td>-0.2201</td>\n","      <td>0.2443</td>\n","      <td>0.4879</td>\n","      <td>0.3432</td>\n","      <td>0.4151</td>\n","      <td>0.9056</td>\n","      <td>0.3538</td>\n","      <td>0.5246</td>\n","      <td>-0.4441</td>\n","      <td>-0.1605</td>\n","      <td>-0.3720</td>\n","      <td>-0.5619</td>\n","      <td>-0.1409</td>\n","      <td>0.1255</td>\n","      <td>0.1214</td>\n","      <td>-0.1975</td>\n","      <td>-0.4367</td>\n","      <td>0.0000</td>\n","      <td>0.4301</td>\n","      <td>-0.7606</td>\n","      <td>-0.0248</td>\n","      <td>0.0270</td>\n","      <td>-0.0367</td>\n","      <td>-1.2480</td>\n","      <td>0.0559</td>\n","      <td>-0.0984</td>\n","      <td>0.5537</td>\n","      <td>0.1063</td>\n","      <td>0.3893</td>\n","      <td>-0.5809</td>\n","      <td>-0.6261</td>\n","      <td>-0.2584</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12297</th>\n","      <td>True</td>\n","      <td>72</td>\n","      <td>0.1608</td>\n","      <td>-1.0500</td>\n","      <td>0.2551</td>\n","      <td>-0.2239</td>\n","      <td>-0.2431</td>\n","      <td>0.4256</td>\n","      <td>-0.1166</td>\n","      <td>-0.1777</td>\n","      <td>-0.7480</td>\n","      <td>0.1368</td>\n","      <td>0.5493</td>\n","      <td>-0.5083</td>\n","      <td>0.4112</td>\n","      <td>0.1181</td>\n","      <td>0.7861</td>\n","      <td>-0.1877</td>\n","      <td>0.2476</td>\n","      <td>0.1956</td>\n","      <td>0.0273</td>\n","      <td>0.1182</td>\n","      <td>-0.5037</td>\n","      <td>-0.5939</td>\n","      <td>0.4825</td>\n","      <td>-0.5187</td>\n","      <td>0.1618</td>\n","      <td>-0.2253</td>\n","      <td>0.3153</td>\n","      <td>0.4839</td>\n","      <td>0.0520</td>\n","      <td>1.3850</td>\n","      <td>0.6502</td>\n","      <td>-0.4198</td>\n","      <td>0.2723</td>\n","      <td>-0.3629</td>\n","      <td>1.0820</td>\n","      <td>-0.0352</td>\n","      <td>0.1911</td>\n","      <td>1.0900</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6009 rows × 2674 columns</p>\n","</div>"],"text/plain":["       with_drug  time     g-0  ...  drug_ffd66e220  drug_ffe357f8f  drug_ffed8e1c9\n","3691        True    24  0.4658  ...               0               0               0\n","3692        True    24 -0.5043  ...               0               0               0\n","3693        True    72  1.1830  ...               0               0               0\n","3694        True    48  1.2070  ...               0               0               0\n","3696        True    72 -0.0890  ...               0               0               0\n","...          ...   ...     ...  ...             ...             ...             ...\n","12291       True    72 -0.5946  ...               0               0               0\n","12293       True    72 -0.4330  ...               0               0               0\n","12294       True    48  0.4123  ...               0               0               0\n","12296       True    48  0.1420  ...               0               0               0\n","12297       True    72  0.1608  ...               0               0               0\n","\n","[6009 rows x 2674 columns]"]},"metadata":{},"execution_count":214}]},{"cell_type":"code","source":["print(f'Train, test, val labels {(train_labels.shape, test_labels.shape, val_labels.shape)}')\n","print(f'Train, test, val features {(train_features.shape, test_features.shape, val_features.shape)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vopDI8d0zB4","executionInfo":{"status":"ok","timestamp":1639526114321,"user_tz":300,"elapsed":114,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"20113f63-3046-4dab-a572-ff10c7304fc2"},"id":"9vopDI8d0zB4","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Train, test, val labels ((3758,), (3244,), (692,))\n","Train, test, val features ((3758, 876), (3244, 876), (692, 876))\n"]}]},{"cell_type":"markdown","metadata":{"id":"IGeiCbGIFiJY"},"source":["### Prediction model\n","* 1 to 4 convolutional neural network (CNN) layers\n","* 1 to 2 bidirectional recurrent neural network (RNN) layers\n","* 1 to 2 fully connected (FC) layers, in a global architecture layout CNN-RNN-FC"],"id":"IGeiCbGIFiJY"},{"cell_type":"code","source":["train_features['label'] = train_labels"],"metadata":{"id":"VV2w72mUNLf8","executionInfo":{"status":"ok","timestamp":1639526119393,"user_tz":300,"elapsed":125,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"VV2w72mUNLf8","execution_count":22,"outputs":[]},{"cell_type":"code","source":["save_path = 'agModels-predictClass'  # specifies folder to store trained models\n","predictor = TabularPredictor(label='label', path=save_path).fit(train_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VomXogTFIuUe","executionInfo":{"status":"ok","timestamp":1639532698824,"user_tz":300,"elapsed":6578546,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"f42ccc97-2a51-484b-994c-51d0e1296c23"},"id":"VomXogTFIuUe","execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictClass\"\n","Beginning AutoGluon training ...\n","AutoGluon will save models to \"agModels-predictClass/\"\n","AutoGluon Version:  0.3.1\n","Train Data Rows:    3758\n","Train Data Columns: 876\n","Preprocessing data ...\n","AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n","\tFirst 10 (of 41) unique label values:  [8, 31, 6, 20, 3, 15, 12, 21, 9, 37]\n","\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n","Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 38 out of 41 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n","Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9957424161788185\n","Train Data Class Count: 38\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    11502.95 MB\n","\tTrain Data (Original)  Memory Usage: 26.32 MB (0.2% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tUseless Original Features (Count: 1): ['with_drug']\n","\t\tThese features carry no predictive signal and should be manually investigated.\n","\t\tThis is typically a feature which has the same value for all rows.\n","\t\tThese features do not need to be present at inference time.\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', [])  : 873 | ['drug', 'g-0', 'g-1', 'g-2', 'g-3', ...]\n","\t\t('int', [])    :   1 | ['time']\n","\t\t('object', []) :   1 | ['dosage']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('float', [])     : 873 | ['drug', 'g-0', 'g-1', 'g-2', 'g-3', ...]\n","\t\t('int', [])       :   1 | ['time']\n","\t\t('int', ['bool']) :   1 | ['dosage']\n","\t1.9s = Fit runtime\n","\t875 features in original data used to generate 875 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 26.17 MB (0.2% of available memory)\n","Data preprocessing and feature engineering runtime = 2.12s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n","\tTo change this, specify the eval_metric argument of fit()\n","Automatically generating train/validation split with holdout_frac=0.13304949441192124, Train Rows: 3244, Val Rows: 498\n","Fitting 13 L1 models ...\n","Fitting model: KNeighborsUnif ...\n","\t0.1827\t = Validation score   (accuracy)\n","\t0.34s\t = Training   runtime\n","\t0.25s\t = Validation runtime\n","Fitting model: KNeighborsDist ...\n","\t0.1847\t = Validation score   (accuracy)\n","\t0.36s\t = Training   runtime\n","\t0.25s\t = Validation runtime\n","Fitting model: NeuralNetFastAI ...\n","No improvement since epoch 3: early stopping\n","\t0.3213\t = Validation score   (accuracy)\n","\t12.66s\t = Training   runtime\n","\t0.35s\t = Validation runtime\n","Fitting model: LightGBMXT ...\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\t0.3213\t = Validation score   (accuracy)\n","\t446.82s\t = Training   runtime\n","\t0.07s\t = Validation runtime\n","Fitting model: LightGBM ...\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\t0.3293\t = Validation score   (accuracy)\n","\t838.64s\t = Training   runtime\n","\t0.28s\t = Validation runtime\n","Fitting model: RandomForestGini ...\n","\t0.2992\t = Validation score   (accuracy)\n","\t56.21s\t = Training   runtime\n","\t0.21s\t = Validation runtime\n","Fitting model: RandomForestEntr ...\n","\t0.2932\t = Validation score   (accuracy)\n","\t229.51s\t = Training   runtime\n","\t0.21s\t = Validation runtime\n","Fitting model: CatBoost ...\n","\t0.2952\t = Validation score   (accuracy)\n","\t1546.24s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: ExtraTreesGini ...\n","\t0.2871\t = Validation score   (accuracy)\n","\t6.77s\t = Training   runtime\n","\t0.21s\t = Validation runtime\n","Fitting model: ExtraTreesEntr ...\n","\t0.2912\t = Validation score   (accuracy)\n","\t8.01s\t = Training   runtime\n","\t0.21s\t = Validation runtime\n","Fitting model: XGBoost ...\n","\t0.3333\t = Validation score   (accuracy)\n","\t1152.36s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Fitting model: NeuralNetMXNet ...\n","\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n","Fitting model: LightGBMLarge ...\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\t0.3153\t = Validation score   (accuracy)\n","\t2256.97s\t = Training   runtime\n","\t0.62s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ...\n","\t0.3655\t = Validation score   (accuracy)\n","\t0.74s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 6578.34s ...\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass/\")\n"]}]},{"cell_type":"code","source":["predictor = TabularPredictor.load(save_path)\n","y_pred = predictor.predict(test_features)\n","print(\"Predictions:  \\n\", y_pred)\n","perf = predictor.evaluate_predictions(y_true=pd.Series(test_labels), y_pred=y_pred, auxiliary_metrics=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzFUMDjmJIDO","executionInfo":{"status":"ok","timestamp":1639537823881,"user_tz":300,"elapsed":10026,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"99fa82d7-0c75-4fe1-fa94-2abbb17d8945"},"id":"vzFUMDjmJIDO","execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluation: accuracy on test data: 0.32244143033292233\n","Evaluations on test data:\n","{\n","    \"accuracy\": 0.32244143033292233,\n","    \"balanced_accuracy\": 0.25574949551137083,\n","    \"mcc\": 0.30117886055652937\n","}\n"]},{"output_type":"stream","name":"stdout","text":["Predictions:  \n"," 0        3\n","1        9\n","2       11\n","3       39\n","4       13\n","        ..\n","3239     8\n","3240    20\n","3241     9\n","3242    30\n","3243     8\n","Name: label, Length: 3244, dtype: int64\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"XpRAtbYQ-avJ","executionInfo":{"status":"ok","timestamp":1639521633900,"user_tz":300,"elapsed":118,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"XpRAtbYQ-avJ","execution_count":351,"outputs":[]},{"cell_type":"code","source":["train_features[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yrKlYyagG2ev","executionInfo":{"status":"ok","timestamp":1639521691561,"user_tz":300,"elapsed":151,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"c48a9809-c0ec-46a6-b123-12a47d601b05"},"id":"yrKlYyagG2ev","execution_count":355,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(876, 1)"]},"metadata":{},"execution_count":355}]},{"cell_type":"code","source":["def bi_LSTM(x_train,y_train):\n","    inputs=Input(shape=(x_train[0].shape), name='inputs')\n","    \n","    dense1 = Dense(32, activation='relu')(inputs)\n","    biLSTM1 = Bidirectional(LSTM(128))(dense1)\n","    drop1 = Dropout(0.3)(biLSTM1)\n","    bn1 = BatchNormalization()(drop1)\n","    dense2 = Dense(64, activation='relu')(bn1)\n","    drop2 = Dropout(0.3)(dense2)\n","    bn2 = BatchNormalization()(drop2)\n","    main_output = Dense(1, activation='softmax')(bn2)\n","\n","    model = Model(inputs= inputs, outputs=main_output, name='BiLSTM_Model')\n","    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])"],"metadata":{"id":"lSOmxxJeGBW9","executionInfo":{"status":"ok","timestamp":1639521882656,"user_tz":300,"elapsed":160,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"lSOmxxJeGBW9","execution_count":365,"outputs":[]},{"cell_type":"code","source":["inputs=Input(shape=(train_features[0].shape), name='inputs')\n","\n","dense1 = Dense(32, activation='relu')(inputs)\n","con1 = Convolution1D(64, (6), activation='relu', name='conv1d_1')(inputs)\n","birnn1 = Bidirectional(SimpleRNN(128))(con1)\n","drop1 = Dropout(0.3)(birnn1)\n","bn1 = BatchNormalization()(drop1)\n","dense2 = Dense(64, activation='relu')(bn1)\n","drop2 = Dropout(0.3)(dense2)\n","bn2 = BatchNormalization()(drop2)\n","main_output = Dense(1, activation='softmax')(bn2)\n","\n","model = Model(inputs= inputs, outputs=main_output, name='BiRNN_Model')\n","model.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thRhyRm9HPga","executionInfo":{"status":"ok","timestamp":1639522020619,"user_tz":300,"elapsed":285,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"e0151caa-bf6d-498b-e70c-c0b87b783bae"},"id":"thRhyRm9HPga","execution_count":370,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"BiRNN_Model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inputs (InputLayer)         [(None, 876, 1)]          0         \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 871, 64)           448       \n","                                                                 \n"," bidirectional_16 (Bidirecti  (None, 256)              49408     \n"," onal)                                                           \n","                                                                 \n"," dropout_29 (Dropout)        (None, 256)               0         \n","                                                                 \n"," batch_normalization_36 (Bat  (None, 256)              1024      \n"," chNormalization)                                                \n","                                                                 \n"," dense_43 (Dense)            (None, 64)                16448     \n","                                                                 \n"," dropout_30 (Dropout)        (None, 64)                0         \n","                                                                 \n"," batch_normalization_37 (Bat  (None, 64)               256       \n"," chNormalization)                                                \n","                                                                 \n"," dense_44 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 67,649\n","Trainable params: 67,009\n","Non-trainable params: 640\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","history1 = model1.fit(convert_to_tensor(train_features, dtype=tf.float64), convert_to_tensor(train_labels, dtype=tf.float64),\n","                      epochs=10, batch_size=64,\n","                      validation_data=(convert_to_tensor(val_features, dtype=tf.float64), convert_to_tensor(val_labels, dtype=tf.float64)),\n","                      callbacks=[es])"],"metadata":{"id":"5jFtAUyXGSsy"},"id":"5jFtAUyXGSsy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def network(X_train,y_train):\n","    im_shape=(X_train.shape[1],1)\n","    inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n","    \n","    # START my code\n","    # convolution layer: \n","    #   filters=64, (last dimension of output from this layer)\n","    #   kernel_size=(6), (2nd dimension of output from this layer is previous layers'-6+1, which means kernel size has to be 6)\n","    conv1d_1 = Convolution1D(64, (6), activation='relu', name='conv1d_1')(inputs_cnn)\n","    # batch normalization\n","    batch_normalization = BatchNormalization(name='batch_normalization')(conv1d_1)\n","    # max pooling:\n","    #   pool_size and strides=2, (2nd output dimension from this layer is 1/2 from 2nd dimension of input to this layer)\n","    #   padding=\"same\" rounds up division of output dimension\n","    max_pooling1d = MaxPool1D(pool_size=2, strides=2, padding='same', name='max_pooling1d')(batch_normalization)\n","    # convolution layer: \n","    #   filters=128, (last dimension of output from this layer)\n","    #   kernel_size=(3), (2nd dimension of output from this layer is previous layers'-3+1, which means kernel size has to be 3)\n","    conv1d_2 = Convolution1D(128, (3), name='conv1d_2')(max_pooling1d)\n","    # batch normalization\n","    batch_normalization_1 = BatchNormalization(name='batch_normalization_1')(conv1d_2)\n","    # max pooling:\n","    #   pool_size and strides=2, (2nd output dimension from this layer is 1/2 from 2nd dimension of input to this layer)\n","    #   padding=\"same\" rounds up division of output dimension\n","    max_pooling1d_1 = MaxPool1D(pool_size=2, strides=2, padding='same', name='max_pooling1d_1')(batch_normalization_1)\n","    # flattening\n","    flatten = Flatten(name='flatten')(max_pooling1d_1)\n","    # fully connected layers\n","    dense = Dense(64, activation='relu', name='dense')(flatten)\n","    dense_1 = Dense(32, activation='relu', name='dense_1')(dense)\n","    main_output = Dense(1, activation='softmax', name='main_output')(dense_1)\n","    # END my code\n","    \n","    model = Model(inputs= inputs_cnn, outputs=main_output, name='model_cnn')\n","    model.compile(optimizer='adam', loss=\"categorical_crossentropy\",metrics = ['accuracy'])\n","\n","    return(model)"],"metadata":{"id":"ag4Ol9zs_hdO","executionInfo":{"status":"ok","timestamp":1639521126327,"user_tz":300,"elapsed":1016,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"ag4Ol9zs_hdO","execution_count":339,"outputs":[]},{"cell_type":"code","source":["model1 = network(train_features, train_labels)\n","print(model1.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0nzu3U__oYQ","executionInfo":{"status":"ok","timestamp":1639521131764,"user_tz":300,"elapsed":302,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"7ac20b5e-b118-4ec6-db53-7c1ef8875d61"},"id":"i0nzu3U__oYQ","execution_count":340,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_cnn\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inputs_cnn (InputLayer)     [(None, 876, 1)]          0         \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 871, 64)           448       \n","                                                                 \n"," batch_normalization (BatchN  (None, 871, 64)          256       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 436, 64)          0         \n"," )                                                               \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 434, 128)          24704     \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 434, 128)         512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 217, 128)         0         \n"," 1D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 27776)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                1777728   \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," main_output (Dense)         (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 1,805,761\n","Trainable params: 1,805,377\n","Non-trainable params: 384\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["from tensorflow import convert_to_tensor\n","import tensorflow as tf\n"],"metadata":{"id":"Aa6MojCJAoRq","executionInfo":{"status":"ok","timestamp":1639520390848,"user_tz":300,"elapsed":141,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"Aa6MojCJAoRq","execution_count":306,"outputs":[]},{"cell_type":"code","source":["es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","history1 = model1.fit(convert_to_tensor(train_features, dtype=tf.float64), convert_to_tensor(train_labels, dtype=tf.float64),\n","                      epochs=10, batch_size=64,\n","                      validation_data=(convert_to_tensor(val_features, dtype=tf.float64), convert_to_tensor(val_labels, dtype=tf.float64)),\n","                      callbacks=[es])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g6ldl1WrDxej","executionInfo":{"status":"ok","timestamp":1639521218847,"user_tz":300,"elapsed":78191,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"84714189-7c55-4bf2-9776-88749fafab5a"},"id":"g6ldl1WrDxej","execution_count":341,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","94/94 [==============================] - 27s 275ms/step - loss: nan - accuracy: 0.0013 - val_loss: nan - val_accuracy: 0.0000e+00\n","Epoch 2/10\n","94/94 [==============================] - 26s 273ms/step - loss: nan - accuracy: 0.0013 - val_loss: nan - val_accuracy: 0.0000e+00\n","Epoch 3/10\n","94/94 [==============================] - 25s 271ms/step - loss: nan - accuracy: 0.0013 - val_loss: nan - val_accuracy: 0.0000e+00\n","Epoch 00003: early stopping\n"]}]},{"cell_type":"code","source":["es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","history1 = model1.fit(train_features, train_labels,\n","                      epochs=10, batch_size=64,\n","                      validation_data=(val_features, val_labels),\n","                      callbacks=[es])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"TLe7Xhwz_uQ-","executionInfo":{"status":"error","timestamp":1639520871241,"user_tz":300,"elapsed":302,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"782b2fe9-4fde-4f74-a61b-ccf10ed3e403"},"id":"TLe7Xhwz_uQ-","execution_count":324,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-324-2f57c80f3fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                       callbacks=[es])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."]}]},{"cell_type":"code","source":["# Implement your code here:\n","# Hint: use an embedding layer to project your sequence data to a higher dimension,\n","# and use the diagram above for some ideas on layers to include in your model.\n","# Remember to compile your model after designing it.\n","\n","x_input = Input(shape=(train_features.shape[1],train_features.shape[2]))\n","# embedding layer\n","e1 = Convolution1D(1, 128)(x_input)\n","# bidirection Dense layer\n","# b1 = Bidirectional(Dense(64, activation='relu', ))(e1)\n","\n","b1 = Bidirectional(SimpleRNN(\n","    4,\n","    activation='relu',\n","    use_bias=True,\n","    kernel_initializer=\"glorot_uniform\",\n","    recurrent_initializer=\"orthogonal\",\n","    bias_initializer=\"zeros\",\n","    kernel_regularizer=None,\n","    recurrent_regularizer=None,\n","    bias_regularizer=None,\n","    activity_regularizer=None,\n","    kernel_constraint=None,\n","    recurrent_constraint=None,\n","    bias_constraint=None,\n","    dropout=0.0,\n","    recurrent_dropout=0.0,\n","    return_sequences=True,\n","    return_state=True,\n","    go_backwards=True,\n","    stateful=False,\n","    unroll=False\n","))(e1)\n","# add some dropout to speed it up/improve model\n","x = Dropout(0.3)(b1)\n","\n","# softmax fully connected layer\n","x_output = Dense(300, activation='softmax')(x)\n","\n","model1 = Model(inputs=x_input, outputs=x_output)\n","model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525},"id":"ICKTIC8C1jXN","executionInfo":{"status":"error","timestamp":1639519695449,"user_tz":300,"elapsed":322,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"f51f69e4-2a3d-4d49-e18c-8cb802916e64"},"id":"ICKTIC8C1jXN","execution_count":280,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-280-582b95f084c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m ))(e1)\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# add some dropout to speed it up/improve model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# softmax fully connected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    532\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             raise ValueError(\n\u001b[0;32m--> 534\u001b[0;31m                 \u001b[0;34mf\"Tried to convert '{input_name}' to a tensor and failed. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m                 f\"Error: {err}\")\n\u001b[1;32m    536\u001b[0m           prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"dropout_6\" (type Dropout).\n\nTried to convert 'input' to a tensor and failed. Error: Shapes must be equal rank, but are 3 and 2\n\tFrom merging shape 0 with other shapes. for '{{node dropout_6/Identity/packed}} = Pack[N=3, T=DT_FLOAT, axis=0](Placeholder, Placeholder_1, Placeholder_2)' with input shapes: [?,749,8], [?,4], [?,4].\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 749, 8), dtype=float32)', 'tf.Tensor(shape=(None, 4), dtype=float32)', 'tf.Tensor(shape=(None, 4), dtype=float32)']\n  • training=None"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"5jr9-V8s1i0t"},"id":"5jr9-V8s1i0t","execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FIO5zovc1iHx"},"id":"FIO5zovc1iHx","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":109,"metadata":{"id":"co2gcIFrFiJc","executionInfo":{"status":"ok","timestamp":1639504840984,"user_tz":300,"elapsed":172,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"outputs":[],"source":["# Evaluation function\n","# added disp_labels as input for confusion matrix\n","def evaluate_model(history, X_test, y_test, model, disp_labels=None):\n","    scores = model.evaluate((X_test),y_test, verbose=0)\n","    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n","    \n","    print(history)\n","    fig1, ax_acc = plt.subplots()\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.title('Model - Accuracy')\n","    plt.legend(['Training', 'Validation'], loc='lower right')\n","    plt.show()\n","    \n","    fig2, ax_loss = plt.subplots()\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Model- Loss')\n","    plt.legend(['Training', 'Validation'], loc='upper right')\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.show()\n","    \n","    prediction_proba = model.predict(X_test)\n","    prediction = np.argmax(prediction_proba, axis=1)\n","\n","    # changed confusion matrix for aesthetics\n","    cnf_matrix = ConfusionMatrixDisplay.from_predictions(y_test, prediction,\n","                                                         cmap='Blues',\n","                         display_labels=disp_labels)"],"id":"co2gcIFrFiJc"},{"cell_type":"code","execution_count":199,"metadata":{"id":"jDuK_h2IFiJd","executionInfo":{"status":"ok","timestamp":1639517673744,"user_tz":300,"elapsed":115,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"outputs":[],"source":["def network(X_train,y_train):\n","    im_shape=(X_train.shape[1],1)\n","    inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n","\n","    # convolution layer: \n","    #   filters=64, (last dimension of output from this layer)\n","    #   kernel_size=(6), (2nd dimension of output from this layer is previous layers'-6+1, which means kernel size has to be 6)\n","    conv1d_1 = Convolution1D(64, (6), activation='relu', name='conv1d_1')(inputs_cnn)\n","    # batch normalization\n","    batch_normalization = BatchNormalization(name='batch_normalization')(inputs_cnn)\n","    # max pooling:\n","    #   pool_size and strides=2, (2nd output dimension from this layer is 1/2 from 2nd dimension of input to this layer)\n","    #   padding=\"same\" rounds up division of output dimension\n","    max_pooling1d = MaxPool1D(pool_size=2, strides=2, padding='same', name='max_pooling1d')(batch_normalization)\n","    # convolution layer: \n","    #   filters=128, (last dimension of output from this layer)\n","    #   kernel_size=(3), (2nd dimension of output from this layer is previous layers'-3+1, which means kernel size has to be 3)\n","    conv1d_2 = Convolution1D(128, (3), name='conv1d_2')(max_pooling1d)\n","    # batch normalization\n","    batch_normalization_1 = BatchNormalization(name='batch_normalization_1')(max_pooling1d)\n","    # max pooling:\n","    #   pool_size and strides=2, (2nd output dimension from this layer is 1/2 from 2nd dimension of input to this layer)\n","    #   padding=\"same\" rounds up division of output dimension\n","    max_pooling1d_1 = MaxPool1D(pool_size=2, strides=2, padding='same', name='max_pooling1d_1')(batch_normalization_1)\n","    # flattening\n","    flatten = Flatten(name='flatten')(max_pooling1d_1)\n","    # fully connected layers\n","    dense = Dense(64, activation='relu', name='dense')(flatten)\n","    dense_1 = Dense(32, activation='relu', name='dense_1')(dense)\n","    main_output = Dense(3, activation='softmax', name='main_output')(dense_1)\n","    # END my code\n","    \n","    model = Model(inputs= inputs_cnn, outputs=main_output, name='model_cnn')\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n","\n","    return(model)"],"id":"jDuK_h2IFiJd"},{"cell_type":"code","source":["model1 = network(train_features, train_labels)\n","print(model1.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDgYBFGcRb2g","executionInfo":{"status":"ok","timestamp":1639517675205,"user_tz":300,"elapsed":298,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"70a5e640-29de-456b-f93b-18b6a3b34d45"},"id":"GDgYBFGcRb2g","execution_count":200,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_cnn\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inputs_cnn (InputLayer)     [(None, 876, 1)]          0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 876, 1)           4         \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 438, 1)           0         \n"," )                                                               \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 438, 1)           4         \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 219, 1)           0         \n"," 1D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 219)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                14080     \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," main_output (Dense)         (None, 3)                 99        \n","                                                                 \n","=================================================================\n","Total params: 16,267\n","Trainable params: 16,263\n","Non-trainable params: 4\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","history1 = model1.fit(train_features, train_labels,\n","                      epochs=10, batch_size=64,\n","                      validation_data=(val_features, val_labels),\n","                      callbacks=[es])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"-wsYvw-HRjXo","executionInfo":{"status":"error","timestamp":1639517679938,"user_tz":300,"elapsed":1200,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"5ddc0232-0454-4262-9153-d5ccd96b5178"},"id":"-wsYvw-HRjXo","execution_count":201,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-201-2f57c80f3fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                       callbacks=[es])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type bool)."]}]},{"cell_type":"code","source":["np.argmax(df_labels.drop('id'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"id":"VyyX_ycvQd9B","executionInfo":{"status":"error","timestamp":1639516748172,"user_tz":300,"elapsed":117,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"3fdb3b38-a2d5-44ab-d88a-c21d7e00a731"},"id":"VyyX_ycvQd9B","execution_count":189,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-189-3aa8d7cb3267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['id'] not found in axis\""]}]},{"cell_type":"code","source":[""],"metadata":{"id":"8D2XkSxmzlyc","executionInfo":{"status":"ok","timestamp":1639516642349,"user_tz":300,"elapsed":146,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"8D2XkSxmzlyc","execution_count":185,"outputs":[]},{"cell_type":"code","source":["# train_labels = one_moa_labels[one_moa_labels.iloc[:, -1] == 'train'].drop(columns=['id', 'dtype']).to_numpy()\n","# train_labels = np.argmax(train_labels, axis=1)\n","# train_labels = keras.utils.to_categorical(\n","#     train_labels, dtype='int32'\n","# )\n","# # train_labels = np.reshape(train_labels, (train_labels.shape[0], train_labels.shape[1], 1)).astype('float')\n","\n","# test_labels = one_moa_labels[one_moa_labels.iloc[:, -1] == 'test'].drop(columns=['id', 'dtype']).to_numpy()\n","# test_labels = np.argmax(test_labels, axis=1)\n","# test_labels = keras.utils.to_categorical(\n","#     test_labels, dtype='int32'\n","# )\n","# # test_labels = np.reshape(test_labels, (test_labels.shape[0], test_labels.shape[1], 1)).astype('float')\n","\n","# val_labels = one_moa_labels[one_moa_labels.iloc[:, -1] == 'val'].drop(columns=['id', 'dtype']).to_numpy()\n","# val_labels = np.argmax(val_labels, axis=1)\n","# val_labels = keras.utils.to_categorical(\n","#     val_labels, dtype='int32'\n","# )\n","# # val_labels = np.reshape(val_labels, (val_labels.shape[0], val_labels.shape[1], 1)).astype('float')\n","\n","# train_features = one_moa_feature[one_moa_feature.iloc[:, -1] == 'train'].drop(columns=['id', 'dtype'])\n","# test_features = one_moa_feature[one_moa_feature.iloc[:, -1] == 'test'].drop(columns=['id', 'dtype'])\n","# val_features = one_moa_feature[one_moa_feature.iloc[:, -1] == 'val'].drop(columns=['id', 'dtype'])"],"metadata":{"id":"tO1Ea4m_Hdyx","executionInfo":{"status":"ok","timestamp":1639516643983,"user_tz":300,"elapsed":279,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"tO1Ea4m_Hdyx","execution_count":186,"outputs":[]},{"cell_type":"code","source":["# Implement your code here:\n","# Hint: use an embedding layer to project your sequence data to a higher dimension,\n","# and use the diagram above for some ideas on layers to include in your model.\n","# Remember to compile your model after designing it.\n","\n","x_input = Input(shape=(train_labels.shape[1],))\n","# embedding layer\n","e1 = Convolution1D(1, 128)(x_input)\n","# bidirection LSTM layer\n","b1 = Bidirectional(Dense(64))(e1)\n","# add some dropout to speed it up/improve model\n","x = Dropout(0.3)(b1)\n","\n","# softmax fully connected layer\n","x_output = Dense(300, activation='softmax')(x)\n","\n","model1 = Model(inputs=x_input, outputs=x_output)\n","model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"JWmcMwKHPN0f","executionInfo":{"status":"error","timestamp":1639507229835,"user_tz":300,"elapsed":126,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"32abff53-19db-40ab-afe5-a90089bc6ec1"},"id":"JWmcMwKHPN0f","execution_count":162,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-162-866104147ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# embedding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# bidirection LSTM layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    228\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                          \u001b[0;34mf'expected min_ndim={spec.min_ndim}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv1d_51\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 171)"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OWZai0ApFiJe"},"outputs":[],"source":["model1 = network(data_train, label_train)\n","print(model1.summary())"],"id":"OWZai0ApFiJe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"XBGFb5QsFiJe"},"outputs":[],"source":["# Train you model\n","# add early stopping to prevent overfitting\n","es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","history1 = model1.fit(data_train, label_train,\n","                      epochs=10, batch_size=64,\n","                      validation_data=(data_val, label_val),\n","                      callbacks=[es])"],"id":"XBGFb5QsFiJe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JFzftqQFFiJe"},"outputs":[],"source":["# Print result and plot accuracy and loss\n","evaluate_model(history1, data_test, label_test, model1)\n","y_pred1 = model1.predict(data_test)"],"id":"JFzftqQFFiJe"},{"cell_type":"code","source":[""],"metadata":{"id":"nFUglzTL0ZIP"},"id":"nFUglzTL0ZIP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Add your code to define a residual block below, as shown in the diagram above\n","def residual_block(data, filters, d_rate, batch_normalize=False):\n","  \"\"\"\n","  _data: input\n","  _filters: convolution filters\n","  _d_rate: dilation rate\n","  \"\"\"\n","\n","  #Add your layers here\n","  # layer 1\n","  if (batch_normalize == True):\n","    data = BatchNormalization()(data)\n","  conv1 = Conv1D(filters, 1, dilation_rate=d_rate, padding='same', activation = 'relu')(data)\n","\n","  # layer 2: bottleneck convolution\n","  if (batch_normalize == True):\n","    conv1 = BatchNormalization()(conv1)\n","  conv2 = Conv1D(filters, 3, padding='same', activation = 'relu')(conv1)\n","\n","  # skip connection\n","  x = Add()([conv2, data])\n","\n","  return x"],"metadata":{"id":"9ml4kqkX0Z8Z","executionInfo":{"status":"ok","timestamp":1639506943607,"user_tz":300,"elapsed":112,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}}},"id":"9ml4kqkX0Z8Z","execution_count":156,"outputs":[]},{"cell_type":"code","source":["#Insert your code before and after the residual networks called below\n","\n","# input\n","x_input = Input(shape=(train_labels.shape[1], train_labels.shape[2]))\n","\n","#initial conv\n","conv = Conv1D(128, 1, padding='same')(x_input) \n","\n","# per-residue representation\n","res1 = residual_block(conv, 128, 2)\n","res2 = residual_block(res1, 128, 3)\n","\n","# Max pooling\n","x = MaxPool1D(3)(res2)\n","x = Dropout(0.5)(x)\n","\n","# softmax classifier\n","x = Flatten()(x)\n","x_output = Dense(300, activation='softmax')(x)\n","\n","#Compile your model\n","model2 = Model(inputs=x_input, outputs=x_output)\n","model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdR_QC-c0diZ","executionInfo":{"status":"ok","timestamp":1639506954747,"user_tz":300,"elapsed":310,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"3fff778f-74c5-4249-f396-e040e301594d"},"id":"CdR_QC-c0diZ","execution_count":158,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_14 (InputLayer)          [(None, 171, 1)]     0           []                               \n","                                                                                                  \n"," conv1d_46 (Conv1D)             (None, 171, 128)     256         ['input_14[0][0]']               \n","                                                                                                  \n"," conv1d_47 (Conv1D)             (None, 171, 128)     16512       ['conv1d_46[0][0]']              \n","                                                                                                  \n"," conv1d_48 (Conv1D)             (None, 171, 128)     49280       ['conv1d_47[0][0]']              \n","                                                                                                  \n"," add_16 (Add)                   (None, 171, 128)     0           ['conv1d_48[0][0]',              \n","                                                                  'conv1d_46[0][0]']              \n","                                                                                                  \n"," conv1d_49 (Conv1D)             (None, 171, 128)     16512       ['add_16[0][0]']                 \n","                                                                                                  \n"," conv1d_50 (Conv1D)             (None, 171, 128)     49280       ['conv1d_49[0][0]']              \n","                                                                                                  \n"," add_17 (Add)                   (None, 171, 128)     0           ['conv1d_50[0][0]',              \n","                                                                  'add_16[0][0]']                 \n","                                                                                                  \n"," max_pooling1d_7 (MaxPooling1D)  (None, 57, 128)     0           ['add_17[0][0]']                 \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 57, 128)      0           ['max_pooling1d_7[0][0]']        \n","                                                                                                  \n"," flatten_4 (Flatten)            (None, 7296)         0           ['dropout_4[0][0]']              \n","                                                                                                  \n"," dense_3 (Dense)                (None, 300)          2189100     ['flatten_4[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,320,940\n","Trainable params: 2,320,940\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# , kernel_regularizer=l2(0.0001)"],"metadata":{"id":"0K3dmBIkLmBV"},"id":"0K3dmBIkLmBV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train you model\n","# add early stopping to prevent overfitting\n","es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","history2 = model2.fit(\n","    x = train_features, \n","    y = train_labels,\n","    epochs=10, batch_size=256,\n","    validation_data = (val_features, val_labels),\n","    callbacks=[es])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"IUdUdcBqHK-8","executionInfo":{"status":"error","timestamp":1639506959130,"user_tz":300,"elapsed":1241,"user":{"displayName":"Sandra Maesta Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXQeQuIVC3cjORzlJOCQ8htwhTCrJJyMbyG0fn=s64","userId":"11990513014675881285"}},"outputId":"e7eccc34-6a7f-4d42-a698-c695a780bc54"},"id":"IUdUdcBqHK-8","execution_count":159,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-159-a04e3ec88df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     callbacks=[es])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type bool)."]}]},{"cell_type":"code","source":[""],"metadata":{"id":"QK7KWto8L795"},"id":"QK7KWto8L795","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"SandraWorkNotebook.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}